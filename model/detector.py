# detector.py - ë©”ì¸ íƒì§€ í´ë˜ìŠ¤

import cv2
import time
import numpy as np
from ultralytics import YOLO

from config import (
    MODEL_PATH, CLASS_NAMES, WEBCAM_CONFIG, 
    DETECTION_CONFIG, DISPLAY_CONFIG
)
from utils import (
    test_gui, stabilize_detections, draw_detections, 
    draw_status_info, create_error_frame, preprocess_frame, print_help
)


class SnackDetector:
    def __init__(self, model_path=None, class_names=None, test_gui_first=True):
        """ìŠ¤ë‚µ íƒì§€ê¸° ì´ˆê¸°í™”"""
        self.model_path = model_path or MODEL_PATH
        self.class_names = class_names or CLASS_NAMES
        
        # GUI í…ŒìŠ¤íŠ¸
        if test_gui_first:
            test_gui()
        
        # ëª¨ë¸ ë¡œë”©
        print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = YOLO(self.model_path)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ìƒíƒœ ë³€ìˆ˜ë“¤
        self.conf_threshold = DETECTION_CONFIG['conf_threshold']
        self.stabilization_mode = True
        self.detection_history = []
        self.last_detections = []
        self.last_successful_frame = None
        
        # FPS ì¸¡ì •
        self.fps_start = time.time()
        self.fps_counter = 0
        self.current_fps = 0
        
        # í”„ë ˆì„ ì¹´ìš´í„°
        self.frame_count = 0
        
        # ì›¹ìº 
        self.cap = None
        
    def init_webcam(self):
        """ì›¹ìº  ì´ˆê¸°í™”"""
        print("ğŸ“¹ ì›¹ìº  ì´ˆê¸°í™” ì¤‘...")
        self.cap = cv2.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, WEBCAM_CONFIG['buffer_size'])
        
        # í•´ìƒë„ ì„¤ì •
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, WEBCAM_CONFIG['width'])
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, WEBCAM_CONFIG['height'])
        
        # MJPEG ì½”ë± ì„¤ì •
        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
        self.cap.set(cv2.CAP_PROP_FOURCC, fourcc)
        self.cap.set(cv2.CAP_PROP_FPS, WEBCAM_CONFIG['fps'])
        
        if not self.cap.isOpened():
            raise Exception("âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        
        # ì‹¤ì œ í•´ìƒë„ í™•ì¸
        self.actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"ğŸ“· ì‹¤ì œ í•´ìƒë„: {self.actual_width}x{self.actual_height}")
        
        # ì›Œë°ì—…
        print("ğŸ”¥ ì›¹ìº  ì›Œë°ì—…...")
        for i in range(10):
            ret, frame = self.cap.read()
            print(f"ì›Œë°ì—… {i+1}: {'OK' if ret else 'FAIL'}")
            time.sleep(0.2)
        
        return True
    
    def setup_display_window(self):
        """ë””ìŠ¤í”Œë ˆì´ ì°½ ì„¤ì •"""
        cv2.namedWindow(DISPLAY_CONFIG['window_name'], cv2.WINDOW_NORMAL)
        cv2.resizeWindow(DISPLAY_CONFIG['window_name'], 
                        DISPLAY_CONFIG['display_width'], 
                        DISPLAY_CONFIG['display_height'])
    
    def process_detections(self, frame):
        """íƒì§€ ìˆ˜í–‰"""
        try:
            print(f"ğŸ” íƒì§€ ì‹¤í–‰... (í”„ë ˆì„ {self.frame_count})")
            
            # í”„ë ˆì„ ì „ì²˜ë¦¬
            processed_frame = preprocess_frame(frame)
            
            start_time = time.time()
            
            # íƒì§€ ìˆ˜í–‰
            results = self.model(processed_frame, conf=self.conf_threshold, verbose=False)
            
            inference_time = time.time() - start_time
            print(f"â±ï¸ ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ")
            
            # ê²°ê³¼ íŒŒì‹±
            current_detections = []
            
            if results and len(results) > 0:
                boxes = results[0].boxes
                
                if boxes is not None and len(boxes) > 0:
                    for box in boxes:
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])
                        
                        if class_id < len(self.class_names):
                            class_name = self.class_names[class_id]
                        else:
                            class_name = f"Unknown_{class_id}"
                        
                        current_detections.append({
                            'bbox': (x1, y1, x2, y2),
                            'name': class_name,
                            'confidence': confidence
                        })
                        
                        print(f"ğŸ¯ íƒì§€: {class_name} ({confidence:.2f})")
            
            # ì•ˆì •í™” ì²˜ë¦¬
            if self.stabilization_mode:
                self.detection_history.append(current_detections)
                if len(self.detection_history) > DETECTION_CONFIG['stabilization_frames']:
                    self.detection_history.pop(0)
                
                self.last_detections = stabilize_detections(self.detection_history, self.class_names)
            else:
                self.last_detections = current_detections
                
        except Exception as e:
            print(f"âš ï¸ íƒì§€ ì˜¤ë¥˜: {e}")
    
    def update_fps(self):
        """FPS ì—…ë°ì´íŠ¸"""
        self.fps_counter += 1
        if self.fps_counter >= 30:
            current_time = time.time()
            self.current_fps = 30 / (current_time - self.fps_start)
            self.fps_start = current_time
            self.fps_counter = 0
    
    def handle_keyboard_input(self, key):
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        if key == ord('q'):
            return False  # ì¢…ë£Œ
        elif key == ord(' '):
            filename = f"detection_{self.frame_count}.jpg"
            # í˜„ì¬ í‘œì‹œ í”„ë ˆì„ ì €ì¥í•˜ê¸° ìœ„í•´ ì—¬ê¸°ì„œëŠ” Trueë§Œ ë°˜í™˜
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ìš”ì²­: {filename}")
            return True
        elif key == ord('s'):
            print(f"ğŸ“Š ìƒíƒœ: í”„ë ˆì„ {self.frame_count}, FPS {self.current_fps:.1f}, íƒì§€ {len(self.last_detections)}ê°œ")
        elif key == ord('+') or key == ord('='):
            self.conf_threshold = min(0.9, self.conf_threshold + 0.05)
            print(f"ğŸ“ˆ ì‹ ë¢°ë„ ì¦ê°€: {self.conf_threshold:.2f}")
        elif key == ord('-'):
            self.conf_threshold = max(0.1, self.conf_threshold - 0.05)
            print(f"ğŸ“‰ ì‹ ë¢°ë„ ê°ì†Œ: {self.conf_threshold:.2f}")
        elif key == ord('f'):
            self.stabilization_mode = not self.stabilization_mode
            print(f"ğŸ”„ ì•ˆì •í™” ëª¨ë“œ: {'ON' if self.stabilization_mode else 'OFF'}")
        
        return True
    
    def run(self):
        """ë©”ì¸ íƒì§€ ë£¨í”„ ì‹¤í–‰"""
        try:
            # ì´ˆê¸°í™”
            self.init_webcam()
            self.setup_display_window()
            print_help()
            
            while True:
                ret, frame = self.cap.read()
                
                # í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ ì²˜ë¦¬
                if not ret or frame is None:
                    print(f"âŒ í”„ë ˆì„ {self.frame_count + 1} ì½ê¸° ì‹¤íŒ¨")
                    
                    if self.last_successful_frame is not None:
                        frame = self.last_successful_frame.copy()
                        cv2.putText(frame, "CAMERA ERROR - USING LAST FRAME", 
                                   (10, self.actual_height-40), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    else:
                        frame = create_error_frame(self.actual_width, self.actual_height)
                else:
                    self.last_successful_frame = frame.copy()
                
                self.frame_count += 1
                self.update_fps()
                
                # íƒì§€ ìˆ˜í–‰ (ë§¤ Ní”„ë ˆì„ë§ˆë‹¤)
                if (self.frame_count % DETECTION_CONFIG['detection_interval'] == 0 and ret):
                    self.process_detections(frame)
                
                # í™”ë©´ í‘œì‹œìš© í”„ë ˆì„ ì¤€ë¹„
                display_frame = frame.copy()
                
                # íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
                display_frame = draw_detections(display_frame, self.last_detections)
                
                # ìƒíƒœ ì •ë³´ ê·¸ë¦¬ê¸°
                display_frame = draw_status_info(
                    display_frame, self.frame_count, self.current_fps, 
                    len(self.last_detections), self.conf_threshold,
                    self.stabilization_mode, ret, 
                    self.actual_width, self.actual_height
                )
                
                # í™”ë©´ ì—…ë°ì´íŠ¸
                try:
                    cv2.imshow(DISPLAY_CONFIG['window_name'], display_frame)
                except Exception as e:
                    print(f"âš ï¸ í™”ë©´ í‘œì‹œ ì˜¤ë¥˜: {e}")
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key != 255:  # í‚¤ê°€ ëˆŒë ¸ì„ ë•Œ
                    if not self.handle_keyboard_input(key):
                        break
                    
                    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    if key == ord(' '):
                        filename = f"detection_{self.frame_count}.jpg"
                        cv2.imwrite(filename, display_frame)
                        print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
                
                # ì§„í–‰ìƒí™© ì£¼ê¸°ì  ì¶œë ¥
                if self.frame_count % 100 == 0:
                    print(f"ğŸ“Š ì§„í–‰: {self.frame_count} í”„ë ˆì„, FPS {self.current_fps:.1f}, ì‹ ë¢°ë„ {self.conf_threshold:.2f}")
            
        except Exception as e:
            print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        finally:
            self.cleanup()
    
    def cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        print("ğŸ”š ê³¼ì íƒì§€ ì¢…ë£Œ")
    
    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.cleanup()