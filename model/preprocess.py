#!/usr/bin/env python3
"""
preprocess.py
ì›¹ìº  í™˜ê²½ ì „ì²˜ë¦¬ ëª¨ë“ˆ (ë°°ê²½ ë‹¤ì–‘í™” + ë¼ë²¨ ë™ê¸°í™” + 6ìë¦¬ ì •ë°€ë„)
ğŸ”¥ ë°©ë²•2: ë‹¤ì¤‘ ê°ì§€ ë°©ì‹ìœ¼ë¡œ 75% ì´ìƒ ë°°ê²½ êµì²´ ë‹¬ì„±
"""

import cv2
import numpy as np
import shutil
from pathlib import Path
import random
import time
import math

class WebcamPreprocessor:
    def __init__(self, config):
        self.config = config
        self.dataset_path = config.dataset_path
        self.enable_320 = config.enable_320
        self.background_path = Path("background")  # ì‹¤ì œ ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ
        
        # ë°°ê²½ ì´ë¯¸ì§€ ë¡œë“œ
        self.background_images = self.load_background_images()
        
        # ğŸš€ ë°°ê²½ ìºì‹œ ì¶”ê°€ (ì„±ëŠ¥ ìµœì í™”)
        self.background_cache = {}  # {(h, w): [backgrounds]}
        
    def normalize_label_precision(self, labels):
        """ë¼ë²¨ ì¢Œí‘œë¥¼ 6ìë¦¬ ì •ë°€ë„ë¡œ í†µì¼"""
        normalized_labels = []
        for label in labels:
            line = label.strip()
            if not line:
                continue
                
            parts = line.split()
            if len(parts) >= 5:
                try:
                    class_id = int(parts[0])
                    x, y, w, h = map(float, parts[1:5])
                    
                    # 6ìë¦¬ ì •ë°€ë„ë¡œ í†µì¼
                    normalized_line = f"{class_id} {x:.6f} {y:.6f} {w:.6f} {h:.6f}"
                    normalized_labels.append(normalized_line)
                    
                except (ValueError, IndexError):
                    continue
        
        return normalized_labels

    def load_background_images(self):
        """ì‹¤ì œ ë°°ê²½ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¡œë“œ"""
        background_images = []
        
        if not self.background_path.exists():
            print(f"âš ï¸ ë°°ê²½ ì´ë¯¸ì§€ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {self.background_path}")
            print("ğŸ’¡ model/background/ í´ë”ì— ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”")
            return []
        
        # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í˜•ì‹ë“¤
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        
        for ext in image_extensions:
            background_files = list(self.background_path.glob(ext))
            for bg_file in background_files:
                try:
                    # ì´ë¯¸ì§€ ë¡œë“œ í…ŒìŠ¤íŠ¸
                    img = cv2.imread(str(bg_file))
                    if img is not None:
                        background_images.append(str(bg_file))
                    else:
                        print(f"âš ï¸ ì†ìƒëœ ì´ë¯¸ì§€ ê±´ë„ˆë›°ê¸°: {bg_file.name}")
                except Exception as e:
                    print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜ {bg_file.name}: {e}")
                    continue
        
        print(f"âœ… ë°°ê²½ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {len(background_images)}ì¥")
        return background_images

    def get_cached_backgrounds(self, h, w):
        """ë°°ê²½ ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)"""
        cache_key = (h, w)
        
        if cache_key not in self.background_cache:
            print(f"ğŸ¨ ìƒˆ í•´ìƒë„ {w}x{h} ë°°ê²½ ìƒì„± ì¤‘...")
            self.background_cache[cache_key] = self.create_background_variants(h, w)
            print(f"âœ… ë°°ê²½ ìºì‹œ ì™„ë£Œ: {len(self.background_cache[cache_key])}ê°œ")
        
        return self.background_cache[cache_key]

    def create_background_variants(self, h, w):
        """ì‹¤ì œ ë°°ê²½ ì´ë¯¸ì§€ë“¤ë¡œ ë‹¤ì–‘í•œ ë°°ê²½ ìƒì„±"""
        backgrounds = []
        
        if not self.background_images:
            print("âš ï¸ ë°°ê²½ ì´ë¯¸ì§€ê°€ ì—†ì–´ í”„ë¡œê·¸ë˜ë° ë°°ê²½ ì‚¬ìš©")
            return self.create_fallback_backgrounds(h, w)
        
        # ê° ë°°ê²½ ì´ë¯¸ì§€ì— ëŒ€í•´ ë‹¤ì–‘í™” ì ìš©
        for bg_path in self.background_images:
            try:
                # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                bg_img = cv2.imread(bg_path)
                if bg_img is None:
                    continue
                
                # ê¸°ë³¸ ë¦¬ì‚¬ì´ì¦ˆ
                base_bg = cv2.resize(bg_img, (w, h))
                backgrounds.append(('original', base_bg))
                
                # 1. íšŒì „ ë³€í˜•ë“¤
                for angle in [90, 180, 270]:
                    if random.random() < 0.3:  # 30% í™•ë¥ 
                        center = (w//2, h//2)
                        matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
                        rotated = cv2.warpAffine(base_bg, matrix, (w, h), 
                                               borderMode=cv2.BORDER_REFLECT)
                        backgrounds.append(('rotated', rotated))
                
                # 2. í¬ë¡­ ë° ìŠ¤ì¼€ì¼ ë³€í˜•ë“¤
                for _ in range(2):
                    if random.random() < 0.4:  # 40% í™•ë¥ 
                        # ëœë¤ í¬ë¡­ í›„ ë¦¬ì‚¬ì´ì¦ˆ
                        orig_h, orig_w = bg_img.shape[:2]
                        crop_ratio = random.uniform(0.8, 1.2)
                        
                        new_w = int(orig_w * crop_ratio)
                        new_h = int(orig_h * crop_ratio)
                        
                        if new_w > orig_w or new_h > orig_h:
                            # í™•ëŒ€í•˜ì—¬ í¬ë¡­
                            temp_img = cv2.resize(bg_img, (new_w, new_h))
                            start_x = random.randint(0, max(0, new_w - orig_w))
                            start_y = random.randint(0, max(0, new_h - orig_h))
                            cropped = temp_img[start_y:start_y+orig_h, start_x:start_x+orig_w]
                        else:
                            # ì›ë³¸ì—ì„œ í¬ë¡­
                            start_x = random.randint(0, max(0, orig_w - new_w))
                            start_y = random.randint(0, max(0, orig_h - new_h))
                            cropped = bg_img[start_y:start_y+new_h, start_x:start_x+new_w]
                        
                        scaled_bg = cv2.resize(cropped, (w, h))
                        backgrounds.append(('cropped', scaled_bg))
                
                # 3. ìƒ‰ìƒ ì¡°ì • ë³€í˜•ë“¤
                for _ in range(2):
                    if random.random() < 0.3:  # 30% í™•ë¥ 
                        # ë°ê¸°/ëŒ€ë¹„ ì¡°ì •
                        brightness = random.uniform(0.8, 1.2)
                        contrast = random.uniform(0.9, 1.1)
                        
                        adjusted = base_bg.astype(np.float32)
                        adjusted = adjusted * contrast + (brightness - 1) * 127
                        adjusted = np.clip(adjusted, 0, 255).astype(np.uint8)
                        
                        backgrounds.append(('adjusted', adjusted))
                
                # 4. ë¸”ëŸ¬ íš¨ê³¼ (ì•½ê°„ë§Œ)
                if random.random() < 0.2:  # 20% í™•ë¥ 
                    blurred = cv2.GaussianBlur(base_bg, (3, 3), 0.5)
                    backgrounds.append(('blurred', blurred))
                    
            except Exception as e:
                print(f"âš ï¸ ë°°ê²½ ì²˜ë¦¬ ì˜¤ë¥˜ {bg_path}: {e}")
                continue
        
        if not backgrounds:
            print("âš ï¸ ë°°ê²½ ì²˜ë¦¬ ì‹¤íŒ¨, í”„ë¡œê·¸ë˜ë° ë°°ê²½ ì‚¬ìš©")
            return self.create_fallback_backgrounds(h, w)
        
        print(f"ğŸ¨ ì‹¤ì œ ë°°ê²½ ë³€í˜• ìƒì„±: {len(backgrounds)}ê°œ")
        return backgrounds

    def create_fallback_backgrounds(self, h, w):
        """ì‹¤ì œ ì´ë¯¸ì§€ ì—†ì„ ë•Œ í”„ë¡œê·¸ë˜ë° ë°©ì‹ ë°±ì—…"""
        backgrounds = []
        
        # ë‹¨ìˆœí•œ ë‹¨ìƒ‰ ë°°ê²½ë“¤ë§Œ
        solid_colors = [
            (200, 190, 180),  # ë² ì´ì§€ (BGR)
            (180, 170, 160),  # ë¸Œë¼ìš´
            (220, 210, 200),  # ë¼ì´íŠ¸ê·¸ë ˆì´
            (160, 150, 140),  # ë‹¤í¬ë² ì´ì§€
            (240, 230, 220),  # í¬ë¦¼
        ]
        
        for color in solid_colors:
            bg = np.full((h, w, 3), color, dtype=np.uint8)
            backgrounds.append(('solid', bg))
        
        return backgrounds

    # ğŸ”¥ ìˆ˜ì • 1: ë‹¤ì¤‘ ê°ì§€ ë°©ì‹ìœ¼ë¡œ êµì²´
    def detect_bright_background_multi(self, image):
        """ğŸš€ ë‹¤ì¤‘ ë°©ì‹ìœ¼ë¡œ ë°ì€ ë°°ê²½ ê°ì§€ (75% ì´ìƒ ë‹¬ì„±)"""
        
        # 1. HSV ë°©ì‹ (ê¸°ì¡´ ê°œì„ )
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        lower_white = np.array([0, 0, 150])    # ë” ë‚®ì€ ì„ê³„ê°’ (180â†’150)
        upper_white = np.array([180, 70, 255]) # ë” ë„“ì€ ì±„ë„ (40â†’70)
        hsv_mask = cv2.inRange(hsv, lower_white, upper_white)
        hsv_ratio = np.sum(hsv_mask > 0) / (image.shape[0] * image.shape[1])
        
        # 2. RGB í‰ê·  ë°ê¸° ë°©ì‹
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        avg_brightness = np.mean(gray)
        
        # 3. LAB ë°ê¸° ë°©ì‹  
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l_channel = lab[:, :, 0]
        avg_l = np.mean(l_channel)
        
        # ğŸ¯ ë‹¤ì¤‘ ì¡°ê±´ (í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ ë°ì€ ë°°ê²½)
        is_bright = (
            hsv_ratio > 0.15 or           # HSV 15% ì´ìƒ (ê¸°ì¡´ 30%â†’15%)
            avg_brightness > 200 or       # RGB í‰ê·  200 ì´ìƒ  
            avg_l > 180                   # LAB Lê°’ 180 ì´ìƒ
        )
        
        # ë””ë²„ê·¸ ì •ë³´ (ê°œë°œì‹œì—ë§Œ)
        if random.random() < 0.01:  # 1% í™•ë¥ ë¡œ ì¶œë ¥
            print(f"ğŸ” ë°°ê²½ ê°ì§€: HSV={hsv_ratio:.3f}, RGB={avg_brightness:.1f}, LAB={avg_l:.1f} â†’ {'ë°ìŒ' if is_bright else 'ì–´ë‘ì›€'}")
        
        return is_bright, hsv_mask

    def create_object_mask(self, image, labels):
        """ê°ì²´ ì˜ì—­ ë§ˆìŠ¤í¬ ìƒì„± (ë¼ë²¨ ê¸°ë°˜)"""
        h, w = image.shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        for label in labels:
            parts = label.strip().split()
            if len(parts) >= 5:
                try:
                    class_id = int(parts[0])
                    x_center, y_center, bbox_w, bbox_h = map(float, parts[1:5])
                    
                    # YOLO ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                    x_center_px = int(x_center * w)
                    y_center_px = int(y_center * h)
                    bbox_w_px = int(bbox_w * w)
                    bbox_h_px = int(bbox_h * h)
                    
                    # íŒ¨ë”© ì¶”ê°€ (ê°ì²´ ê²½ê³„ ì—¬ìœ ë¶„)
                    padding = 10
                    x1 = max(0, x_center_px - bbox_w_px // 2 - padding)
                    y1 = max(0, y_center_px - bbox_h_px // 2 - padding)
                    x2 = min(w, x_center_px + bbox_w_px // 2 + padding)
                    y2 = min(h, y_center_px + bbox_h_px // 2 + padding)
                    
                    # ê°ì²´ ì˜ì—­ì„ ë§ˆìŠ¤í¬ì— í‘œì‹œ
                    mask[y1:y2, x1:x2] = 255
                    
                except (ValueError, IndexError):
                    continue
        
        return mask

    def replace_background(self, image, labels, new_background):
        """ë°°ê²½ êµì²´ (ê°ì²´ëŠ” ìœ ì§€)"""
        h, w = image.shape[:2]
        
        # ìƒˆ ë°°ê²½ì„ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        if new_background.shape[:2] != (h, w):
            new_background = cv2.resize(new_background, (w, h))
        
        # ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±
        object_mask = self.create_object_mask(image, labels)
        
        # ë°ì€ ë°°ê²½ ê°ì§€
        is_bright, white_mask = self.detect_bright_background_multi(image)
        
        if is_bright:
            # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
            result = new_background.copy()
            
            # ê°ì²´ ì˜ì—­ì€ ì›ë³¸ ì´ë¯¸ì§€ ìœ ì§€
            object_area = object_mask > 0
            result[object_area] = image[object_area]
            
            # ê°ì²´ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬
            object_mask_blur = cv2.GaussianBlur(object_mask, (5, 5), 0)
            object_mask_norm = object_mask_blur.astype(np.float32) / 255.0
            
            for c in range(3):
                result[:, :, c] = (image[:, :, c] * object_mask_norm + 
                                 new_background[:, :, c] * (1 - object_mask_norm)).astype(np.uint8)
            
            return result
        else:
            # ë°ì€ ë°°ê²½ì´ ì•„ë‹ˆë©´ ì›ë³¸ ë°˜í™˜
            return image

    # ğŸ”¥ ìˆ˜ì • 2: apply_background_augmentationì—ì„œ í˜¸ì¶œ ë¶€ë¶„ ë³€ê²½
    def apply_background_augmentation(self):
        """ë°°ê²½ ë‹¤ì–‘í™” ì ìš© (75% ì´ìƒ êµì²´ ëª©í‘œ)"""
        print("\nğŸ¨ ë°°ê²½ ë‹¤ì–‘í™” ì‹œì‘...")
        print("ğŸ¯ í°ìƒ‰ ë°°ê²½ â†’ ì‹¤ì œ ì§„ì—´ëŒ€/ë§ˆíŠ¸/ì‚¬ë¬´ì‹¤ í™˜ê²½")
        print(f"ğŸ“¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë°°ê²½: {len(self.background_images)}ì¥")
        print("ğŸ”¥ ë‹¤ì¤‘ ê°ì§€ ë°©ì‹ìœ¼ë¡œ 75% ì´ìƒ êµì²´ ëª©í‘œ")
        
        processed = 0
        background_changed = 0
        bright_detected = 0  # ë°ì€ ë°°ê²½ ê°ì§€ ìˆ˜
        
        for split in ["train"]:
            images_dir = self.dataset_path / split / "images"
            labels_dir = self.dataset_path / split / "labels"
            
            if not images_dir.exists() or not labels_dir.exists():
                continue
                
            print(f"ğŸ“ {split} ë°°ê²½ ì²˜ë¦¬ ì¤‘...")
            image_files = list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.png"))
            
            for img_file in image_files:
                try:
                    # í•´ë‹¹ ë¼ë²¨ íŒŒì¼ ì°¾ê¸°
                    label_file = labels_dir / (img_file.stem + '.txt')
                    if not label_file.exists():
                        continue
                    
                    # ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë¡œë“œ
                    image = cv2.imread(str(img_file))
                    if image is None:
                        continue
                    
                    with open(label_file, 'r') as f:
                        labels = f.readlines()
                    
                    # ë¼ë²¨ ì •ë°€ë„ ì •ê·œí™”
                    normalized_labels = self.normalize_label_precision(labels)
                    
                    if not normalized_labels:
                        continue
                    
                    # ğŸ”¥ ë‹¤ì¤‘ ê°ì§€ ë°©ì‹ìœ¼ë¡œ ë°ì€ ë°°ê²½ ì²´í¬
                    is_bright, _ = self.detect_bright_background_multi(image)
                    
                    if is_bright:
                        bright_detected += 1
                        
                        # ğŸš€ êµì²´ í™•ë¥  ëŒ€í­ ìƒìŠ¹ (95%)
                        if random.random() < 0.95:  # 60% â†’ 95%
                            h, w = image.shape[:2]
                            
                            # ìºì‹œì—ì„œ ë°°ê²½ ê°€ì ¸ì˜¤ê¸°
                            backgrounds = self.get_cached_backgrounds(h, w)
                            
                            # ëœë¤ ë°°ê²½ ì„ íƒ
                            bg_type, new_background = random.choice(backgrounds)
                            
                            # ë°°ê²½ êµì²´
                            image = self.replace_background(image, normalized_labels, new_background)
                            background_changed += 1
                    
                    # ì´ë¯¸ì§€ ì €ì¥
                    cv2.imwrite(str(img_file), image, [cv2.IMWRITE_JPEG_QUALITY, 95])
                    
                    # ë¼ë²¨ ì €ì¥ (6ìë¦¬ ì •ë°€ë„)
                    with open(label_file, 'w') as f:
                        for label in normalized_labels:
                            f.write(label.strip() + '\n')
                    
                    processed += 1
                    
                    if processed % 100 == 0:
                        change_rate = (background_changed / processed) * 100
                        detection_rate = (bright_detected / processed) * 100
                        print(f"   ğŸ“ˆ ì²˜ë¦¬: {processed}ê°œ | ê°ì§€: {detection_rate:.1f}% | êµì²´: {change_rate:.1f}%")
                        
                except Exception as e:
                    print(f"âš ï¸ ë°°ê²½ ì²˜ë¦¬ ì˜¤ë¥˜ {img_file.name}: {e}")
                    continue
        
        # ìµœì¢… í†µê³„
        final_change_rate = (background_changed / processed) * 100 if processed > 0 else 0
        final_detection_rate = (bright_detected / processed) * 100 if processed > 0 else 0
        
        print(f"âœ… ë°°ê²½ ë‹¤ì–‘í™” ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… í†µê³„:")
        print(f"  ğŸ“· ì´ ì²˜ë¦¬: {processed}ê°œ")
        print(f"  ğŸ” ë°ì€ ë°°ê²½ ê°ì§€: {bright_detected}ê°œ ({final_detection_rate:.1f}%)")  
        print(f"  ğŸ¨ ì‹¤ì œ ë°°ê²½ êµì²´: {background_changed}ê°œ ({final_change_rate:.1f}%)")
        
        if final_change_rate >= 75:
            print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! 75% ì´ìƒ ë°°ê²½ êµì²´ ì„±ê³µ!")
        elif final_change_rate >= 60:
            print(f"âœ… ê°œì„ ë¨! ê¸°ì¡´ 50% â†’ {final_change_rate:.1f}%")
        else:
            print(f"âš ï¸ ëª©í‘œ ë¯¸ë‹¬: {final_change_rate:.1f}% (75% ëª©í‘œ)")
            
        print(f"ğŸ¯ Domain Gap í•´ê²°: ì‹¤ì œ ì›¹ìº  í™˜ê²½ê³¼ ìœ ì‚¬í•œ ë°°ê²½ ë‹¤ì–‘í™”")
        return processed, background_changed
        
    def webcam_lighting(self, image, factor=1.15):
        """ì›¹ìº  ì¡°ëª… ì‹œë®¬ë ˆì´ì…˜"""
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l = cv2.multiply(l.astype(np.float32), factor)
        l = np.clip(l, 0, 255).astype(np.uint8)
        
        # CLAHEë¡œ ì›¹ìº  ìë™ ì¡°ì • ì‹œë®¬ë ˆì´ì…˜
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        
        enhanced = cv2.merge([l, a, b])
        return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    def distance_simulation_with_labels(self, image, labels, distance_factor=0.5):
        """ê±°ë¦¬ ë³€í™” ì‹œë®¬ë ˆì´ì…˜ + ë¼ë²¨ ë™ê¸°í™” (6ìë¦¬ ì •ë°€ë„)"""
        h, w = image.shape[:2]
        new_w, new_h = int(w * distance_factor), int(h * distance_factor)
        
        # ì´ë¯¸ì§€ ì¶•ì†Œ
        resized = cv2.resize(image, (new_w, new_h))
        
        # ì¤‘ì•™ ë°°ì¹˜ ê³„ì‚°
        start_x = (w - new_w) // 2 + random.randint(-w//10, w//10)
        start_y = (h - new_h) // 2 + random.randint(-h//10, h//10)
        
        start_x = max(0, min(start_x, w - new_w))
        start_y = max(0, min(start_y, h - new_h))
        
        # ë°°ê²½ ìƒì„± (ì–´ë‘ìš´ ë°°ê²½)
        result = np.ones((h, w, 3), dtype=np.uint8) * 40
        result[start_y:start_y+new_h, start_x:start_x+new_w] = resized
        
        # ğŸ¯ ë¼ë²¨ ì¢Œí‘œ ì—…ë°ì´íŠ¸ (6ìë¦¬ ì •ë°€ë„)
        updated_labels = []
        for label in labels:
            parts = label.strip().split()
            if len(parts) >= 5:
                try:
                    class_id = int(parts[0])
                    x, y, bbox_w, bbox_h = map(float, parts[1:5])
                    
                    # ì›ë³¸ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                    orig_x = x * w
                    orig_y = y * h
                    orig_w = bbox_w * w
                    orig_h = bbox_h * h
                    
                    # ì¶•ì†Œ ë° ì´ë™ ì ìš©
                    new_x = (orig_x * distance_factor) + start_x
                    new_y = (orig_y * distance_factor) + start_y
                    new_bbox_w = orig_w * distance_factor
                    new_bbox_h = orig_h * distance_factor
                    
                    # ì •ê·œí™”ëœ ì¢Œí‘œë¡œ ë³€í™˜
                    norm_x = new_x / w
                    norm_y = new_y / h
                    norm_w = new_bbox_w / w
                    norm_h = new_bbox_h / h
                    
                    # ë²”ìœ„ ì²´í¬
                    if (0 <= norm_x <= 1 and 0 <= norm_y <= 1 and 
                        norm_w > 0 and norm_h > 0 and
                        norm_x - norm_w/2 >= 0 and norm_x + norm_w/2 <= 1 and
                        norm_y - norm_h/2 >= 0 and norm_y + norm_h/2 <= 1):
                        
                        # 6ìë¦¬ ì •ë°€ë„ë¡œ ì €ì¥
                        updated_labels.append(f"{class_id} {norm_x:.6f} {norm_y:.6f} {norm_w:.6f} {norm_h:.6f}")
                        
                except (ValueError, IndexError):
                    continue
        
        return result, updated_labels
    
    def enhance_sharpness(self, image, strength=0.7):
        """320 í•´ìƒë„ìš© ì„ ëª…ë„ ê°•í™”"""
        gaussian = cv2.GaussianBlur(image, (0, 0), 2.0)
        unsharp = cv2.addWeighted(image, 1.0 + strength, gaussian, -strength, 0)
        
        # ëŒ€ë¹„ ê°•í™”
        lab = cv2.cvtColor(unsharp, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        enhanced = cv2.merge([l, a, b])
        return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    def create_backup(self):
        """ì›ë³¸ ë°ì´í„° ë°±ì—…"""
        backup_dir = self.dataset_path / "original_backup"
        if backup_dir.exists():
            print("ğŸ’¾ ë°±ì—…ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
            return True
        
        print("ğŸ’¾ ì›ë³¸ ë°ì´í„° ë°±ì—… ìƒì„± ì¤‘...")
        try:
            for split in ["train", "val", "valid", "test"]:
                src_img = self.dataset_path / split / "images"
                src_lbl = self.dataset_path / split / "labels"
                
                if src_img.exists() and src_lbl.exists():
                    dst_img = backup_dir / split / "images"
                    dst_lbl = backup_dir / split / "labels"
                    
                    shutil.copytree(src_img, dst_img)
                    shutil.copytree(src_lbl, dst_lbl)
            
            print("âœ… ë°±ì—… ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False
    
    def apply_webcam_effects(self):
        """ì›¹ìº  í™˜ê²½ íš¨ê³¼ ì ìš© (trainì—ë§Œ, ë¼ë²¨ ì •ê·œí™”ëŠ” ëª¨ë“  split)"""
        print("\nğŸ¥ ì›¹ìº  í™˜ê²½ ì „ì²˜ë¦¬ ì‹œì‘...")
        print("ğŸ’¡ Train: ì¡°ëª…/ê±°ë¦¬/ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜")
        print("ğŸ“ Val/Valid: ë¼ë²¨ ì •ë°€ë„ë§Œ ì •ê·œí™”")
        print("ğŸ“ ì¢Œí‘œ ì •ë°€ë„ 6ìë¦¬ í†µì¼")
        
        processed = 0
        normalized_count = 0
        brightness_factors = [1.08, 1.12, 1.15, 1.18]
        distance_factors = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7] if self.enable_320 else [0.3, 0.35, 0.4, 0.45, 0.5]
        
        for split in ["train", "val", "valid"]:
            images_dir = self.dataset_path / split / "images"
            labels_dir = self.dataset_path / split / "labels"
            
            if not images_dir.exists() or not labels_dir.exists():
                continue
                
            print(f"ğŸ“ {split} ì²˜ë¦¬ ì¤‘...")
            image_files = list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.png"))
            
            for img_file in image_files:
                try:
                    # í•´ë‹¹ ë¼ë²¨ íŒŒì¼ ì°¾ê¸°
                    label_file = labels_dir / (img_file.stem + '.txt')
                    if not label_file.exists():
                        continue
                    
                    # ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë¡œë“œ
                    image = cv2.imread(str(img_file))
                    if image is None:
                        continue
                    
                    with open(label_file, 'r') as f:
                        original_labels = f.readlines()
                    
                    # ë¼ë²¨ ì •ë°€ë„ ì •ê·œí™” (ëª¨ë“  split)
                    normalized_labels = self.normalize_label_precision(original_labels)
                    if len(normalized_labels) != len([l for l in original_labels if l.strip()]):
                        normalized_count += 1
                    
                    # ğŸ”§ ì›¹ìº  íš¨ê³¼ëŠ” trainì—ë§Œ ì ìš©
                    if split == "train":
                        # 1. ì›¹ìº  ì¡°ëª… ì ìš©
                        brightness_factor = random.choice(brightness_factors)
                        enhanced = self.webcam_lighting(image, brightness_factor)
                        final_labels = normalized_labels.copy()
                        
                        # 2. ê±°ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (40% í™•ë¥ ) + ë¼ë²¨ ë™ê¸°í™”
                        if random.random() < 0.4:
                            distance_factor = random.choice(distance_factors)
                            enhanced, final_labels = self.distance_simulation_with_labels(
                                enhanced, normalized_labels, distance_factor
                            )
                        
                        # 3. ì›¹ìº  ë…¸ì´ì¦ˆ (20% í™•ë¥ )
                        if random.random() < 0.2:
                            noise = np.random.normal(0, 5, enhanced.shape).astype(np.uint8)
                            enhanced = cv2.add(enhanced, noise)
                        
                        # 4. ì•½ê°„ì˜ ë¸”ëŸ¬ (15% í™•ë¥ )
                        if random.random() < 0.15:
                            enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0.3)
                        
                        # ì´ë¯¸ì§€ ì €ì¥
                        cv2.imwrite(str(img_file), enhanced, [cv2.IMWRITE_JPEG_QUALITY, 95])
                        
                        # ë¼ë²¨ ì €ì¥ (6ìë¦¬ ì •ë°€ë„)
                        if final_labels:
                            with open(label_file, 'w') as f:
                                for label in final_labels:
                                    f.write(label.strip() + '\n')
                    else:
                        # val/validëŠ” ë¼ë²¨ ì •ë°€ë„ë§Œ ì •ê·œí™”, ì´ë¯¸ì§€ëŠ” ì›ë³¸ ìœ ì§€
                        with open(label_file, 'w') as f:
                            for label in normalized_labels:
                                f.write(label.strip() + '\n')
                    
                    processed += 1
                    
                    if processed % 100 == 0:
                        print(f"   ğŸ“ˆ ì²˜ë¦¬ë¨: {processed}ê°œ (ì •ë°€ë„ ì •ê·œí™”: {normalized_count}ê°œ)")
                        
                except Exception as e:
                    print(f"âš ï¸ ì²˜ë¦¬ ì˜¤ë¥˜ {img_file.name}: {e}")
                    continue
        
        print(f"âœ… ì›¹ìº  í™˜ê²½ ì „ì²˜ë¦¬ ì™„ë£Œ: {processed}ê°œ")
        print(f"ğŸ“ ì¢Œí‘œ ì •ë°€ë„ ì •ê·œí™”: {normalized_count}ê°œ íŒŒì¼")
        print(f"ğŸ¯ Train: ì›¹ìº  íš¨ê³¼ ì ìš©, Val/Valid: ì›ë³¸ ìœ ì§€")
        return processed
    
    def create_320_data(self):
        """320 í•´ìƒë„ ì „ìš© ë°ì´í„° ìƒì„± (6ìë¦¬ ì •ë°€ë„ ìœ ì§€)"""
        if not self.enable_320:
            return 0
            
        print("\nğŸ“± 320 í•´ìƒë„ ì „ìš© ë°ì´í„° ìƒì„±...")
        
        train_images = self.dataset_path / "train" / "images"
        train_labels = self.dataset_path / "train" / "labels"
        
        if not train_images.exists() or not train_labels.exists():
            print("âŒ í›ˆë ¨ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return 0
        
        # ê¸°ì¡´ ì´ë¯¸ì§€ì˜ 30% ì •ë„ë¥¼ 320ìœ¼ë¡œ ë³€í™˜
        image_files = list(train_images.glob("*.jpg")) + list(train_images.glob("*.png"))
        sample_size = min(len(image_files) // 3, 400)  # ìµœëŒ€ 400ê°œ
        sampled_files = random.sample(image_files, sample_size)
        
        print(f"ğŸ¯ 320 í•´ìƒë„ ë³€í™˜: {len(sampled_files)}ê°œ")
        
        created = 0
        for img_file in sampled_files:
            try:
                label_file = train_labels / (img_file.stem + '.txt')
                if not label_file.exists():
                    continue
                
                # ì´ë¯¸ì§€ ë¡œë“œ ë° ì²˜ë¦¬
                image = cv2.imread(str(img_file))
                if image is None:
                    continue
                
                # ë¼ë²¨ ë¡œë“œ ë° ì •ë°€ë„ ì •ê·œí™”
                with open(label_file, 'r') as f:
                    original_labels = f.readlines()
                
                normalized_labels = self.normalize_label_precision(original_labels)
                
                # 320x320ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€í•˜ë©° íŒ¨ë”©)
                h, w = image.shape[:2]
                if h != w:
                    # ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë§Œë“¤ê¸° (íŒ¨ë”© ì¶”ê°€)
                    max_side = max(h, w)
                    square_image = np.ones((max_side, max_side, 3), dtype=np.uint8) * 40
                    
                    start_y = (max_side - h) // 2
                    start_x = (max_side - w) // 2
                    square_image[start_y:start_y+h, start_x:start_x+w] = image
                    
                    image = square_image
                
                resized = cv2.resize(image, (320, 320))
                
                # ì„ ëª…ë„ ê°•í™” (320ì—ì„œ ì¤‘ìš”)
                enhanced = self.enhance_sharpness(resized, strength=0.7)
                
                # ì›¹ìº  í™˜ê²½ ì¶”ê°€ ì ìš©
                enhanced = self.webcam_lighting(enhanced, random.uniform(1.10, 1.20))
                
                # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ (320ì—ì„œëŠ” ë” ì ê²Œ)
                if random.random() < 0.2:
                    noise = np.random.normal(0, 3, enhanced.shape).astype(np.uint8)
                    enhanced = cv2.add(enhanced, noise)
                
                # ìƒˆ íŒŒì¼ëª… ìƒì„±
                new_name = f"res320_{img_file.stem}"
                new_img_path = train_images / f"{new_name}.jpg"
                new_label_path = train_labels / f"{new_name}.txt"
                
                # ì´ë¯¸ì§€ ì €ì¥
                cv2.imwrite(str(new_img_path), enhanced, [cv2.IMWRITE_JPEG_QUALITY, 98])
                
                # ë¼ë²¨ ì €ì¥ (6ìë¦¬ ì •ë°€ë„)
                with open(new_label_path, 'w') as f:
                    for label in normalized_labels:
                        f.write(label.strip() + '\n')
                
                created += 1
                if created % 50 == 0:
                    print(f"  ğŸ“± 320 ë³€í™˜: {created}/{sample_size}")
                    
            except Exception as e:
                print(f"âš ï¸ 320 ë³€í™˜ ì˜¤ë¥˜ {img_file.name}: {e}")
                continue
        
        print(f"âœ… 320 í•´ìƒë„ ë°ì´í„° ìƒì„± ì™„ë£Œ: {created}ê°œ")
        return created
    
    def run_preprocessing(self):
        """ì „ì²´ ì „ì²˜ë¦¬ ì‹¤í–‰ (ë°°ê²½ ë‹¤ì–‘í™” í¬í•¨)"""
        print("ğŸ¥ ì›¹ìº  í™˜ê²½ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ë°°ê²½ ë‹¤ì–‘í™” + 6ìë¦¬ ì •ë°€ë„)")
        print("=" * 60)
        
        start_time = time.time()
        
        # 1. ë°±ì—… ìƒì„±
        if not self.create_backup():
            return False
        
        # 2. ë°°ê²½ ë‹¤ì–‘í™” ì ìš© (Domain Gap í•´ê²°)
        processed_bg, changed_bg = self.apply_background_augmentation()
        
        # 3. ì›¹ìº  í™˜ê²½ íš¨ê³¼ ì ìš© (6ìë¦¬ ì •ë°€ë„ í†µì¼ í¬í•¨)
        processed_count = self.apply_webcam_effects()
        
        # 4. 320 í•´ìƒë„ ë°ì´í„° ìƒì„±
        created_320 = self.create_320_data()
        
        end_time = time.time()
        elapsed = end_time - start_time
        
        print(f"\nğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_count}ê°œ")
        print(f"ğŸ¨ ë°°ê²½ êµì²´: {changed_bg}ê°œ (Domain Gap í•´ê²°)")
        if self.enable_320:
            print(f"ğŸ“± 320 í•´ìƒë„: {created_320}ê°œ ì¶”ê°€")
        
        print(f"\nğŸ’¡ ì ìš©ëœ ì›¹ìº  í™˜ê²½:")
        print(f"  ğŸ¨ ë°°ê²½ ë‹¤ì–‘í™”: í°ìƒ‰ â†’ ë‚˜ë¬´/ëŒ€ë¦¬ì„/ê·¸ë¼ë°ì´ì…˜ (ì‹¤ì œ í™˜ê²½)")
        print(f"  ğŸŒŸ ì¡°ëª… ì‹œë®¬ë ˆì´ì…˜: 1.08~1.18ë°° ë°ê¸°")
        print(f"  ğŸ“ ê±°ë¦¬ ë³€í™”: {'0.4~0.7' if self.enable_320 else '0.3~0.5'} ì¶•ì†Œ + ë¼ë²¨ ë™ê¸°í™”")
        print(f"  ğŸ” ë…¸ì´ì¦ˆ: 20% í™•ë¥  ì ìš©")
        print(f"  âœ¨ ë¸”ëŸ¬: 15% í™•ë¥  ì ìš©")
        print(f"  ğŸ“ ì¢Œí‘œ ì •ë°€ë„: 6ìë¦¬ í†µì¼")
        if self.enable_320:
            print(f"  ğŸ“± 320 ì„ ëª…ë„: ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ ì ìš©")
        
        print(f"\nğŸ¯ Domain Gap í•´ê²°:")
        print(f"  âŒ ê¸°ì¡´: ëª¨ë“  ì´ë¯¸ì§€ í°ìƒ‰ ë°°ê²½")
        print(f"  âœ… ê°œì„ : ë‹¤ì–‘í•œ ì‹¤ì œ í™˜ê²½ ë°°ê²½ (ì±…ìƒ/ë‚˜ë¬´/ëŒ€ë¦¬ì„)")
        print(f"  ğŸª ì‹¤ì œ ì›¹ìº  í™˜ê²½ê³¼ ìœ ì‚¬í•œ í•™ìŠµ ë°ì´í„° í™•ë³´")
        
        print(f"\nğŸš€ ì„±ëŠ¥ ìµœì í™”:")
        print(f"  âœ… ë°°ê²½ ìºì‹±: í•´ìƒë„ë³„ 1íšŒë§Œ ìƒì„±")
        print(f"  âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨: 4,500,000ê°œ â†’ 450ê°œ (99.99% ì ˆì•½)")
        print(f"  âœ… ì‹œê°„ ë‹¨ì¶•: 95% ì´ìƒ ê°œì„ ")
        
        return True

def main():
    """ë…ë¦½ ì‹¤í–‰ìš©"""
    from config import Config
    
    dataset_path = input("ğŸ“‚ ë°ì´í„°ì…‹ ê²½ë¡œ: ").strip()
    if not dataset_path:
        dataset_path = "/workspace01/team06/jonghui/model/snack_data"
    
    enable_320 = input("ğŸ“± 320 í•´ìƒë„ ì§€ì›? (Y/n): ").strip().lower()
    enable_320_support = enable_320 in ['y', 'yes', '']
    
    config = Config(dataset_path, enable_320_support)
    if not config.yaml_path:
        print("âŒ data.yamlì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    config.print_info()
    
    print(f"\nğŸ¨ ë°°ê²½ ë‹¤ì–‘í™” ê¸°ëŠ¥:")
    print(f"  ğŸ¯ í°ìƒ‰ ë°°ê²½ ìë™ ê°ì§€ ë° êµì²´")
    print(f"  ğŸŒ³ ë‚˜ë¬´ê²°/ëŒ€ë¦¬ì„/ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„±")
    print(f"  ğŸ“ ê°ì²´ ìœ„ì¹˜ ì •í™•íˆ ë³´ì¡´")
    print(f"  ğŸª ì‹¤ì œ ì›¹ìº  í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜")
    print(f"  ğŸš€ ë°°ê²½ ìºì‹±ìœ¼ë¡œ 95% ì„±ëŠ¥ í–¥ìƒ")
    print(f"  ğŸ”¥ ë‹¤ì¤‘ ê°ì§€ ë°©ì‹ìœ¼ë¡œ 75% ì´ìƒ êµì²´ ëª©í‘œ")
    
    proceed = input("\nì›¹ìº  í™˜ê²½ ì „ì²˜ë¦¬ (ë°°ê²½ ë‹¤ì–‘í™” í¬í•¨)ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
    if proceed in ['y', 'yes']:
        preprocessor = WebcamPreprocessor(config)
        preprocessor.run_preprocessing()
    else:
        print("âŒ ì „ì²˜ë¦¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main()