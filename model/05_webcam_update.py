""" í…ŒìŠ¤íŠ¸ìš© .pt í™•ì¥ìì—ì„œë§Œ ë™ì‘í•¨ """

import cv2
import time
from ultralytics import YOLO
import numpy as np
from collections import defaultdict, deque

def calculate_iou(box1, box2):
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IoU ê³„ì‚°"""
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x1_inter = max(x1_1, x1_2)
    y1_inter = max(y1_1, y1_2)
    x2_inter = min(x2_1, x2_2)
    y2_inter = min(y2_1, y2_2)
    
    if x2_inter <= x1_inter or y2_inter <= y1_inter:
        return 0.0
    
    # êµì§‘í•© ë„“ì´
    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)
    
    # ê° ë°•ìŠ¤ì˜ ë„“ì´
    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
    
    # í•©ì§‘í•© ë„“ì´
    union_area = box1_area + box2_area - inter_area
    
    return inter_area / union_area if union_area > 0 else 0.0

def calculate_distance(box1, box2):
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ì  ê°„ì˜ ê±°ë¦¬ ê³„ì‚°"""
    x1_center = (box1[0] + box1[2]) / 2
    y1_center = (box1[1] + box1[3]) / 2
    x2_center = (box2[0] + box2[2]) / 2
    y2_center = (box2[1] + box2[3]) / 2
    
    return np.sqrt((x1_center - x2_center)**2 + (y1_center - y2_center)**2)

class ObjectTracker:
    """Level 2 Multi-frame Voting ê¸°ë°˜ ê°ì²´ ì¶”ì ê¸°"""
    
    def __init__(self, max_history=15, min_votes=8, iou_threshold=0.3, distance_threshold=50):
        self.max_history = max_history  # ìµœëŒ€ íˆìŠ¤í† ë¦¬ í”„ë ˆì„ ìˆ˜
        self.min_votes = min_votes      # ìµœì†Œ íˆ¬í‘œ ìˆ˜ (ìœ íš¨ ê°ì²´ íŒì •)
        self.iou_threshold = iou_threshold      # IoU ì„ê³„ê°’ (ê°™ì€ ê°ì²´ íŒì •)
        self.distance_threshold = distance_threshold  # ê±°ë¦¬ ì„ê³„ê°’
        
        # íƒì§€ íˆìŠ¤í† ë¦¬ ì €ì¥
        self.detection_history = deque(maxlen=max_history)
        
        # ì•ˆì •í™”ëœ ê°ì²´ë“¤
        self.stable_objects = []
        
        # í†µê³„ ì •ë³´
        self.class_counts = defaultdict(int)
        self.total_objects = 0
        
    def update(self, current_detections):
        """ìƒˆë¡œìš´ í”„ë ˆì„ì˜ íƒì§€ ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸"""
        # í˜„ì¬ íƒì§€ ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.detection_history.append(current_detections)
        
        # Multi-frame Voting ìˆ˜í–‰
        self.stable_objects = self._perform_voting()
        
        # ê°œìˆ˜ í†µê³„ ì—…ë°ì´íŠ¸
        self._update_statistics()
        
        return self.stable_objects
    
    def _perform_voting(self):
        """Multi-frame Voting ì•Œê³ ë¦¬ì¦˜ ìˆ˜í–‰"""
        if len(self.detection_history) < 3:  # ìµœì†Œ 3í”„ë ˆì„ í•„ìš”
            return []
        
        # 1ë‹¨ê³„: ëª¨ë“  íƒì§€ ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
        class_groups = defaultdict(list)
        
        for frame_idx, detections in enumerate(self.detection_history):
            for detection in detections:
                class_name = detection['name']
                class_groups[class_name].append({
                    'detection': detection,
                    'frame_idx': frame_idx,
                    'timestamp': len(self.detection_history) - frame_idx  # ìµœì‹ ë„
                })
        
        stable_objects = []
        
        # 2ë‹¨ê³„: í´ë˜ìŠ¤ë³„ë¡œ ê³µê°„ì  í´ëŸ¬ìŠ¤í„°ë§ ë° íˆ¬í‘œ
        for class_name, detections in class_groups.items():
            if len(detections) < 3:  # ë„ˆë¬´ ì ì€ íƒì§€ëŠ” ì œì™¸
                continue
            
            # ê³µê°„ì  í´ëŸ¬ìŠ¤í„°ë§
            clusters = self._spatial_clustering(detections)
            
            # ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´ íˆ¬í‘œ ìˆ˜í–‰
            for cluster in clusters:
                votes = len(cluster)
                if votes >= self.min_votes:
                    # í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ ê°ì²´ ìƒì„±
                    representative = self._create_representative(cluster)
                    if representative:
                        stable_objects.append(representative)
        
        return stable_objects
    
    def _spatial_clustering(self, detections):
        """ê³µê°„ì  í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰"""
        clusters = []
        used_indices = set()
        
        for i, detection1 in enumerate(detections):
            if i in used_indices:
                continue
            
            # ìƒˆ í´ëŸ¬ìŠ¤í„° ì‹œì‘
            cluster = [detection1]
            used_indices.add(i)
            
            bbox1 = detection1['detection']['bbox']
            
            # ë¹„ìŠ·í•œ ìœ„ì¹˜ì˜ ë‹¤ë¥¸ íƒì§€ë“¤ ì°¾ê¸°
            for j, detection2 in enumerate(detections):
                if j in used_indices:
                    continue
                
                bbox2 = detection2['detection']['bbox']
                
                # IoU ë˜ëŠ” ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê°™ì€ ê°ì²´ íŒì •
                iou = calculate_iou(bbox1, bbox2)
                distance = calculate_distance(bbox1, bbox2)
                
                if iou > self.iou_threshold or distance < self.distance_threshold:
                    cluster.append(detection2)
                    used_indices.add(j)
            
            clusters.append(cluster)
        
        return clusters
    
    def _create_representative(self, cluster):
        """í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ ê°ì²´ ìƒì„±"""
        if not cluster:
            return None
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìœ„ì¹˜ ê³„ì‚° (ìµœì‹  í”„ë ˆì„ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        total_weight = 0
        weighted_x1, weighted_y1, weighted_x2, weighted_y2 = 0, 0, 0, 0
        max_confidence = 0
        class_name = cluster[0]['detection']['name']
        
        for item in cluster:
            detection = item['detection']
            weight = item['timestamp']  # ìµœì‹ ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
            bbox = detection['bbox']
            confidence = detection['confidence']
            
            weighted_x1 += bbox[0] * weight
            weighted_y1 += bbox[1] * weight
            weighted_x2 += bbox[2] * weight
            weighted_y2 += bbox[3] * weight
            total_weight += weight
            
            max_confidence = max(max_confidence, confidence)
        
        if total_weight == 0:
            return None
        
        # í‰ê·  ìœ„ì¹˜ ê³„ì‚°
        avg_bbox = (
            int(weighted_x1 / total_weight),
            int(weighted_y1 / total_weight),
            int(weighted_x2 / total_weight),
            int(weighted_y2 / total_weight)
        )
        
        # íˆ¬í‘œ ìˆ˜ ê³„ì‚° (ì‹ ë¢°ë„ ë°˜ì˜)
        vote_score = len(cluster) / self.max_history
        stability_score = min(1.0, len(cluster) / self.min_votes)
        
        return {
            'bbox': avg_bbox,
            'name': class_name,
            'confidence': max_confidence,
            'votes': len(cluster),
            'vote_score': vote_score,
            'stability': stability_score
        }
    
    def _update_statistics(self):
        """í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸"""
        self.class_counts = defaultdict(int)
        
        for obj in self.stable_objects:
            self.class_counts[obj['name']] += 1
        
        self.total_objects = len(self.stable_objects)
    
    def get_count_summary(self):
        """í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ìš”ì•½ ë°˜í™˜"""
        return dict(self.class_counts), self.total_objects

def improved_webcam_detection():
    """Level 2 Multi-frame Voting ê¸°ë°˜ ì›¹ìº  íƒì§€"""
    print("ğŸª Level 2 Multi-frame Voting ê°ì²´ ê°œìˆ˜ íŒŒì•… ì‹œìŠ¤í…œ")
    
    # ë¨¼ì € GUI í…ŒìŠ¤íŠ¸
    print("ğŸ§ª GUI ê¸°ë³¸ í…ŒìŠ¤íŠ¸...")
    test_img = np.zeros((200, 400, 3), dtype=np.uint8)
    test_img[50:150, 50:350] = [0, 255, 0]
    cv2.putText(test_img, "GUI Working!", (100, 110), 
               cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    cv2.namedWindow('GUI Test', cv2.WINDOW_NORMAL)
    cv2.imshow('GUI Test', test_img)
    print("GUI í…ŒìŠ¤íŠ¸ ì°½ì´ ë³´ì´ë‚˜ìš”? 2ì´ˆ í›„ ìë™ìœ¼ë¡œ ë‹«í™ë‹ˆë‹¤.")
    cv2.waitKey(2000)
    cv2.destroyAllWindows()
    
    # ëª¨ë¸ ë¡œë”©
    model_path = "/home/paper/workspace/MartAGVrobot_Martkeeper/model/best.pt"
    print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = YOLO(model_path)
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # í´ë˜ìŠ¤ëª…
    class_names = ['crown_BigPie_Strawberry_324G', 'crown_ChocoHaim_142G', 'crown_Concho_66G',
                   'crown_Potto_Cheese_Tart_322G', 'haetae_Guun_Gamja_162G', 'haetae_HoneyButterChip_38G',
                   'haetae_Masdongsan_90G', 'haetae_Osajjeu_60G', 'haetae_Oyeseu_360G',
                   'lotte_kkokkalkon_gosohanmas_72G', 'nongshim_Alsaeuchip_68G', 'nongshim_Banana_Kick_75G',
                   'nongshim_ChipPotato_Original_125G', 'nongshim_Ojingeojip_83G' ,'orion_Chocolate_Chip_Cookies_256G',
                   'orion_Diget_Choco_312G', 'orion_Diget_tongmil_28_194G', 'orion_Fresh_Berry_336G',
                   'orion_Gosomi_80G', 'orion_Pocachip_Original_66G', 'orion_chokchokhan_Chocochip_240G'
                   ]
    
    # ê°ì²´ ì¶”ì ê¸° ì´ˆê¸°í™”
    tracker = ObjectTracker(
        max_history=15,    # 15í”„ë ˆì„ íˆìŠ¤í† ë¦¬
        min_votes=8,       # ìµœì†Œ 8í”„ë ˆì„ì—ì„œ íƒì§€ë˜ì–´ì•¼ ìœ íš¨
        iou_threshold=0.3, # IoU 30% ì´ìƒì´ë©´ ê°™ì€ ê°ì²´
        distance_threshold=50  # ê±°ë¦¬ 50í”½ì…€ ì´ë‚´ë©´ ê°™ì€ ê°ì²´
    )
    
    # ì›¹ìº  ì´ˆê¸°í™”
    print("ğŸ“¹ ì›¹ìº  ì´ˆê¸°í™” ì¤‘...")
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    # USB 2.0ì— ìµœì í™”ëœ í•´ìƒë„
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)
    
    # MJPEG ì½”ë±ìœ¼ë¡œ ì••ì¶• íš¨ìœ¨ í–¥ìƒ
    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
    cap.set(cv2.CAP_PROP_FOURCC, fourcc)
    cap.set(cv2.CAP_PROP_FPS, 10)
    
    if not cap.isOpened():
        print("âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        return
    
    # ì‹¤ì œ í•´ìƒë„ í™•ì¸
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"ğŸ“· ì‹¤ì œ í•´ìƒë„: {actual_width}x{actual_height}")
    
    # ì›Œë°ì—…
    print("ğŸ”¥ ì›¹ìº  ì›Œë°ì—…...")
    for i in range(10):
        ret, frame = cap.read()
        print(f"ì›Œë°ì—… {i+1}: {'OK' if ret else 'FAIL'}")
        time.sleep(0.2)
    
    # OpenCV ì°½ ë¯¸ë¦¬ ìƒì„± ë° ì„¤ì •
    window_name = 'Level 2 Object Counting System'
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 800, 600)
    
    print("ğŸ¯ Level 2 ê°ì²´ ê°œìˆ˜ íŒŒì•… ì‹œì‘!")
    print("ì£¼ìš” ì¡°ì‘:")
    print("  'q': ì¢…ë£Œ")
    print("  'SPACE': ìŠ¤í¬ë¦°ìƒ·")
    print("  's': í†µê³„ ì¶œë ¥")
    print("  '+/-': ì‹ ë¢°ë„ ì¡°ì ˆ")
    print("  'r': ì¶”ì ê¸° ë¦¬ì…‹")
    print("  'c': ê°œìˆ˜ ì¹´ìš´íŒ… ë³´ê³ ì„œ")
    
    frame_count = 0
    conf_threshold = 0.25
    last_successful_frame = None
    
    # FPS ì¸¡ì •
    fps_start = time.time()
    fps_counter = 0
    current_fps = 0
    
    # ê°œìˆ˜ ë³´ê³ ì„œ ë³€ìˆ˜
    count_history = deque(maxlen=100)  # ìµœê·¼ 100í”„ë ˆì„ì˜ ê°œìˆ˜ ê¸°ë¡
    
    while True:
        ret, frame = cap.read()
        
        if not ret or frame is None:
            print(f"âŒ í”„ë ˆì„ {frame_count + 1} ì½ê¸° ì‹¤íŒ¨")
            
            if last_successful_frame is not None:
                frame = last_successful_frame.copy()
                cv2.putText(frame, "CAMERA ERROR - USING LAST FRAME", (10, actual_height-40), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                frame = np.zeros((actual_height, actual_width, 3), dtype=np.uint8)
                cv2.putText(frame, "CAMERA ERROR", (actual_width//2-100, actual_height//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        else:
            last_successful_frame = frame.copy()
        
        frame_count += 1
        fps_counter += 1
         
        # FPS ê³„ì‚°
        if fps_counter >= 30:
            current_time = time.time()
            current_fps = 30 / (current_time - fps_start)
            fps_start = current_time
            fps_counter = 0
        
        # íƒì§€ëŠ” ë§¤ 3í”„ë ˆì„ë§ˆë‹¤
        if frame_count % 3 == 0 and ret:
            try:
                print(f"ğŸ” íƒì§€ ì‹¤í–‰... (í”„ë ˆì„ {frame_count})")
                
                # í”„ë ˆì„ ì „ì²˜ë¦¬
                processed_frame = cv2.convertScaleAbs(frame, alpha=1.1, beta=5)
                
                start_time = time.time()
                
                # YOLO íƒì§€
                results = model(processed_frame, conf=conf_threshold, verbose=False)
                
                inference_time = time.time() - start_time
                print(f"â±ï¸ ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ")
                
                # í˜„ì¬ í”„ë ˆì„ íƒì§€ ê²°ê³¼
                current_detections = []
                
                if results and len(results) > 0:
                    boxes = results[0].boxes
                    
                    if boxes is not None and len(boxes) > 0:
                        for box in boxes:
                            x1, y1, x2, y2 = map(int, box.xyxy[0])
                            confidence = float(box.conf[0])
                            class_id = int(box.cls[0])
                            
                            if class_id < len(class_names):
                                class_name = class_names[class_id]
                            else:
                                class_name = f"Unknown_{class_id}"
                            
                            current_detections.append({
                                'bbox': (x1, y1, x2, y2),
                                'name': class_name,
                                'confidence': confidence
                            })
                            
                            print(f"ğŸ¯ íƒì§€: {class_name} ({confidence:.2f})")
                
                # ì¶”ì ê¸° ì—…ë°ì´íŠ¸ (Level 2 Multi-frame Voting)
                stable_objects = tracker.update(current_detections)
                
                # ê°œìˆ˜ í†µê³„ ê¸°ë¡
                class_counts, total_count = tracker.get_count_summary()
                count_history.append({
                    'frame': frame_count,
                    'total': total_count,
                    'classes': dict(class_counts)
                })
                
            except Exception as e:
                print(f"âš ï¸ íƒì§€ ì˜¤ë¥˜: {e}")
                stable_objects = []
        else:
            stable_objects = tracker.stable_objects
        
        # í™”ë©´ í‘œì‹œìš© í”„ë ˆì„ ì¤€ë¹„
        display_frame = frame.copy()
        
        # ì•ˆì •í™”ëœ ê°ì²´ë“¤ ê·¸ë¦¬ê¸°
        for obj in stable_objects:
            x1, y1, x2, y2 = obj['bbox']
            class_name = obj['name']
            confidence = obj['confidence']
            votes = obj['votes']
            stability = obj['stability']
            
            # ì•ˆì •ì„±ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€ê²½
            if stability > 0.8:
                color = (0, 255, 0)      # ë§¤ìš° ì•ˆì •: ì´ˆë¡ìƒ‰
            elif stability > 0.6:
                color = (0, 255, 255)    # ì•ˆì •: ë…¸ë€ìƒ‰
            elif stability > 0.4:
                color = (0, 165, 255)    # ë³´í†µ: ì£¼í™©ìƒ‰
            else:
                color = (255, 0, 255)    # ë¶ˆì•ˆì •: ë³´ë¼ìƒ‰
            
            # ë°”ìš´ë”© ë°•ìŠ¤ (ë‘ê»˜ëŠ” ì•ˆì •ì„±ì— ë¹„ë¡€)
            thickness = max(1, int(stability * 4))
            cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, thickness)
            
            # ë¼ë²¨ (íˆ¬í‘œ ìˆ˜ì™€ ì•ˆì •ì„± í¬í•¨)
            label = f"{class_name}"
            confidence_label = f"Conf:{confidence:.2f}"
            stability_label = f"Votes:{votes}/Stab:{stability:.2f}"
            
            cv2.putText(display_frame, label, (x1, y1-30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            cv2.putText(display_frame, confidence_label, (x1, y1-15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            cv2.putText(display_frame, stability_label, (x1, y1-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # í˜„ì¬ ê°œìˆ˜ í†µê³„ í‘œì‹œ
        class_counts, total_count = tracker.get_count_summary()
        
        # ìƒíƒœ ì •ë³´ í‘œì‹œ (ì™¼ìª½)
        cv2.putText(display_frame, f"Frame: {frame_count}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(display_frame, f"FPS: {current_fps:.1f}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(display_frame, f"Total Objects: {total_count}", (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(display_frame, f"Conf Threshold: {conf_threshold:.2f}", (10, 120), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ í‘œì‹œ (ì˜¤ë¥¸ìª½)
        y_offset = 30
        cv2.putText(display_frame, "Class Counts:", (actual_width-200, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        for class_name, count in class_counts.items():
            if count > 0:
                y_offset += 25
                short_name = class_name.split('_')[0] if '_' in class_name else class_name[:10]
                cv2.putText(display_frame, f"{short_name}: {count}", 
                           (actual_width-200, y_offset), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ì¹´ë©”ë¼ ìƒíƒœ í‘œì‹œ
        status_color = (0, 255, 0) if ret else (0, 0, 255)
        status_text = "CAM OK" if ret else "CAM ERROR"
        cv2.putText(display_frame, status_text, (actual_width-150, actual_height-20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
        
        # í™”ë©´ ì—…ë°ì´íŠ¸
        try:
            cv2.imshow(window_name, display_frame)
        except Exception as e:
            print(f"âš ï¸ í™”ë©´ í‘œì‹œ ì˜¤ë¥˜: {e}")
        
        # í‚¤ ì…ë ¥ ì²˜ë¦¬
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            print("ì‚¬ìš©ì ì¢…ë£Œ ìš”ì²­")
            break
        elif key == ord(' '):
            filename = f"level2_detection_{frame_count}.jpg"
            cv2.imwrite(filename, display_frame)
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
        elif key == ord('s'):
            print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ:")
            print(f"  í”„ë ˆì„: {frame_count}, FPS: {current_fps:.1f}")
            print(f"  ì´ ê°ì²´: {total_count}")
            print(f"  í´ë˜ìŠ¤ë³„: {dict(class_counts)}")
        elif key == ord('+') or key == ord('='):
            conf_threshold = min(0.9, conf_threshold + 0.05)
            print(f"ğŸ“ˆ ì‹ ë¢°ë„ ì¦ê°€: {conf_threshold:.2f}")
        elif key == ord('-'):
            conf_threshold = max(0.1, conf_threshold - 0.05)
            print(f"ğŸ“‰ ì‹ ë¢°ë„ ê°ì†Œ: {conf_threshold:.2f}")
        elif key == ord('r'):
            tracker = ObjectTracker(max_history=15, min_votes=8, iou_threshold=0.3, distance_threshold=50)
            print("ğŸ”„ ì¶”ì ê¸° ë¦¬ì…‹ ì™„ë£Œ")
        elif key == ord('c'):
            print_count_report(count_history, class_counts, total_count)
        
        # ì§„í–‰ìƒí™© ì£¼ê¸°ì  ì¶œë ¥
        if frame_count % 100 == 0:
            print(f"ğŸ“Š ì§„í–‰: {frame_count} í”„ë ˆì„, FPS {current_fps:.1f}, ì´ ê°ì²´ {total_count}ê°œ")
    
    # ì •ë¦¬
    cap.release()
    cv2.destroyAllWindows()
    print("ğŸ”š Level 2 ê°ì²´ ê°œìˆ˜ íŒŒì•… ì‹œìŠ¤í…œ ì¢…ë£Œ")

def print_count_report(count_history, current_counts, current_total):
    """ê°œìˆ˜ ì¹´ìš´íŒ… ë³´ê³ ì„œ ì¶œë ¥"""
    print("\n" + "="*60)
    print("ğŸ“Š Level 2 Multi-frame Voting ê°œìˆ˜ íŒŒì•… ë³´ê³ ì„œ")
    print("="*60)
    
    if not count_history:
        print("âŒ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìµœê·¼ ë°ì´í„° ë¶„ì„
    recent_counts = list(count_history)[-20:]  # ìµœê·¼ 20í”„ë ˆì„
    
    # ì•ˆì •ì„± ë¶„ì„
    total_counts = [entry['total'] for entry in recent_counts]
    if total_counts:
        avg_total = sum(total_counts) / len(total_counts)
        std_total = np.std(total_counts)
        stability = 1.0 - (std_total / max(avg_total, 1))
        
        print(f"ğŸ“ˆ ì´ ê°ì²´ ìˆ˜ ì•ˆì •ì„±:")
        print(f"  í˜„ì¬: {current_total}ê°œ")
        print(f"  í‰ê· : {avg_total:.1f}ê°œ")
        print(f"  í‘œì¤€í¸ì°¨: {std_total:.2f}")
        print(f"  ì•ˆì •ì„±: {stability:.2f} ({'ì•ˆì •' if stability > 0.8 else 'ë¶ˆì•ˆì •'})")
    
    # í´ë˜ìŠ¤ë³„ ìƒì„¸ ë¶„ì„
    print(f"\nğŸ·ï¸ í´ë˜ìŠ¤ë³„ ê°œìˆ˜ í˜„í™©:")
    for class_name, count in current_counts.items():
        if count > 0:
            # ìµœê·¼ íˆìŠ¤í† ë¦¬ì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ ë¶„ì„
            class_history = []
            for entry in recent_counts:
                class_history.append(entry['classes'].get(class_name, 0))
            
            if class_history:
                avg_count = sum(class_history) / len(class_history)
                std_count = np.std(class_history)
                class_stability = 1.0 - (std_count / max(avg_count, 1))
                
                short_name = class_name.split('_')[0] if '_' in class_name else class_name
                status = "ğŸŸ¢" if class_stability > 0.8 else "ğŸŸ¡" if class_stability > 0.6 else "ğŸ”´"
                
                print(f"  {status} {short_name}: {count}ê°œ (í‰ê· :{avg_count:.1f}, ì•ˆì •ì„±:{class_stability:.2f})")
    
    print(f"\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
    if stability > 0.8:
        print("  âœ… ê°œìˆ˜ íŒŒì•…ì´ ì•ˆì •ì ì…ë‹ˆë‹¤. í˜„ì¬ ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif stability > 0.6:
        print("  ğŸŸ¡ ê°œìˆ˜ê°€ ì•½ê°„ ë³€ë™ë©ë‹ˆë‹¤. ëª‡ ì´ˆ ë” ê´€ì°°í•´ë³´ì„¸ìš”.")
    else:
        print("  âš ï¸ ê°œìˆ˜ê°€ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ì¡°ëª…ì´ë‚˜ ì¹´ë©”ë¼ ê°ë„ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
    
    print("="*60 + "\n")

if __name__ == "__main__":
    improved_webcam_detection()