""" 02_setting_instance.py """ 

import os
import cv2
import numpy as np
import albumentations as A
import shutil
from pathlib import Path
import json
import random
from collections import Counter, defaultdict
import yaml
import time
import math

try:
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
from datetime import datetime

class BalancedDatasetManager:
    """YOLO ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ê· í˜• ì¡°ì ˆ ê´€ë¦¬ì (ë‹¨ìˆœ ì¦í­ ë°©ì‹)"""
    
    def __init__(self, dataset_path, target_instances=600, min_instances=100):
        self.dataset_path = Path(dataset_path)
        self.target_instances = target_instances
        self.min_instances = min_instances
        
        # data.yaml ë¡œë“œ
        self.load_dataset_config()
        
        print(f"ğŸ“Š YOLO ë°ì´í„°ì…‹ ê· í˜• ì¡°ì ˆ ê´€ë¦¬ì (ë‹¨ìˆœ ì¦í­)")
        print(f"ğŸ“‚ ë°ì´í„°ì…‹: {dataset_path}")
        print(f"ğŸ¯ ëª©í‘œ: {target_instances}ê°œ/í´ë˜ìŠ¤")
        print(f"ğŸ“ í´ë˜ìŠ¤: {len(self.class_names)}ê°œ")
        print(f"ğŸ”§ ë°©ì‹: ì „ì²´ ì´ë¯¸ì§€ ì¦ê°• (ë¼ë²¨ ì •í™•ì„± ë³´ì¥)")

    def load_dataset_config(self):
        """data.yaml ì„¤ì • ë¡œë“œ"""
        yaml_path = self.dataset_path / "data.yaml"
        
        if not yaml_path.exists():
            raise FileNotFoundError(f"data.yaml not found: {yaml_path}")
        
        with open(yaml_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.class_names = self.config['names']
        self.num_classes = self.config['nc']
        
        print(f"âœ… ì„¤ì • ë¡œë“œ: {self.num_classes}ê°œ í´ë˜ìŠ¤")
        for i, name in enumerate(self.class_names):
            print(f"   {i}: {name}")

    def analyze_instance_distribution(self):
        """í´ë˜ìŠ¤ë³„ ì¸ìŠ¤í„´ìŠ¤ ë¶„í¬ ë¶„ì„"""
        print("\nğŸ“Š í´ë˜ìŠ¤ë³„ ì¸ìŠ¤í„´ìŠ¤ ë¶„í¬ ë¶„ì„...")
        
        instance_counts = Counter()
        image_sources = defaultdict(list)  # ì´ë¯¸ì§€ ê¸°ë°˜ ì†ŒìŠ¤ë¡œ ë³€ê²½
        bbox_data = defaultdict(list)
        all_bboxes = []
        
        # train í´ë”ë§Œ ë¶„ì„ (ì¦ê°•ì€ trainì—ì„œë§Œ ìˆ˜í–‰)
        labels_dir = self.dataset_path / "train" / "labels"
        images_dir = self.dataset_path / "train" / "images"
        
        if not labels_dir.exists():
            raise FileNotFoundError(f"Train labels directory not found: {labels_dir}")
        
        total_files = 0
        for label_file in labels_dir.glob("*.txt"):
            # í•´ë‹¹ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            image_file = None
            for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:
                potential_image = images_dir / (label_file.stem + ext)
                if potential_image.exists():
                    image_file = potential_image
                    break
            
            if not image_file:
                continue
                
            total_files += 1
            
            try:
                with open(label_file, 'r') as f:
                    lines = f.readlines()
                
                # ì´ ì´ë¯¸ì§€ì— í¬í•¨ëœ í´ë˜ìŠ¤ë“¤ ìˆ˜ì§‘
                image_classes = set()
                image_bbox_data = []
                
                for line_idx, line in enumerate(lines):
                    line = line.strip()
                    if line:
                        parts = line.split()
                        if len(parts) >= 5:
                            try:
                                class_id = int(parts[0])
                                x, y, w, h = map(float, parts[1:5])
                                
                                # ìœ íš¨í•œ í´ë˜ìŠ¤ ID ì²´í¬
                                if 0 <= class_id < self.num_classes:
                                    instance_counts[class_id] += 1
                                    image_classes.add(class_id)
                                    
                                    # ë°”ìš´ë”©ë°•ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
                                    bbox_info = {
                                        'class_id': class_id,
                                        'x_center': x,
                                        'y_center': y,
                                        'width': w,
                                        'height': h,
                                        'area': w * h
                                    }
                                    bbox_data[class_id].append(bbox_info)
                                    all_bboxes.append(bbox_info)
                                    image_bbox_data.append(bbox_info)
                                    
                            except (ValueError, IndexError):
                                continue
                
                # ì´ë¯¸ì§€ë³„ ì†ŒìŠ¤ ì •ë³´ ì €ì¥ (í´ë˜ìŠ¤ë³„ë¡œ)
                for class_id in image_classes:
                    class_bboxes = [bbox for bbox in image_bbox_data if bbox['class_id'] == class_id]
                    
                    image_info = {
                        'image_path': str(image_file),
                        'label_path': str(label_file),
                        'labels': lines,
                        'target_class': class_id,
                        'class_count': len(class_bboxes),
                        'total_objects': len(image_bbox_data),
                        'is_single_class': len(image_classes) == 1,
                        'has_small_objects': any(bbox['area'] < 0.01 for bbox in class_bboxes)
                    }
                    image_sources[class_id].append(image_info)
                    
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {label_file.name}: {e}")
                continue
        
        total_instances = sum(instance_counts.values())
        avg_instances = total_instances / self.num_classes if self.num_classes > 0 else 0
        
        print(f"\nğŸ“ˆ ë¶„ì„ ê²°ê³¼:")
        print(f"   ì´ íŒŒì¼: {total_files}ê°œ")
        print(f"   ì´ ì¸ìŠ¤í„´ìŠ¤: {total_instances}ê°œ")
        print(f"   í‰ê· : {avg_instances:.1f}ê°œ/í´ë˜ìŠ¤")
        print(f"   ëª©í‘œ: {self.target_instances}ê°œ/í´ë˜ìŠ¤")
        
        # ì‹œê°í™” ìƒì„±
        if MATPLOTLIB_AVAILABLE:
            self.create_distribution_analysis(instance_counts, bbox_data, all_bboxes)
        else:
            print("âš ï¸ matplotlibì´ ì—†ì–´ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. ì„¤ì¹˜: pip install matplotlib")
        
        # í´ë˜ìŠ¤ë³„ ìƒì„¸ ì •ë³´
        print(f"\n{'ID':<3} {'í´ë˜ìŠ¤ëª…':<30} {'í˜„ì¬':<8} {'ëª©í‘œ':<8} {'ë¶€ì¡±':<8} {'ìƒíƒœ':<12}")
        print("-" * 80)
        
        augmentation_plans = {}
        
        for class_id in range(self.num_classes):
            class_name = self.class_names[class_id]
            current_count = instance_counts.get(class_id, 0)
            shortage = max(0, self.target_instances - current_count)
            
            if current_count >= self.target_instances:
                status = "âœ… ë‹¬ì„±"
            elif current_count >= self.target_instances * 0.8:
                status = "ğŸŸ¡ ì•½ê°„ë¶€ì¡±"
                strategy = 'light'
            elif current_count >= self.target_instances * 0.5:
                status = "ğŸŸ  ë¶€ì¡±"
                strategy = 'moderate'
            elif current_count >= self.min_instances:
                status = "ğŸ”´ ë§¤ìš°ë¶€ì¡±"
                strategy = 'aggressive'
            else:
                status = "âŒ ê·¹ì†ŒëŸ‰"
                strategy = 'extreme'
            
            print(f"{class_id:<3} {class_name:<30} {current_count:<8} {self.target_instances:<8} {shortage:<8} {status:<12}")
            
            # ì¦ê°• ê³„íš ìƒì„±
            if shortage > 0 and current_count >= 5:  # ìµœì†Œ 5ê°œ ì´ìƒ ìˆì–´ì•¼ ì¦ê°• ê°€ëŠ¥
                # í•´ë‹¹ í´ë˜ìŠ¤ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ë“¤ ì„ ë³„
                class_images = image_sources.get(class_id, [])
                if class_images:
                    augmentation_plans[class_id] = {
                        'name': class_name,
                        'current': current_count,
                        'needed': shortage,
                        'sources': class_images,
                        'strategy': strategy,
                        'source_images': len(class_images)
                    }
        
        return augmentation_plans, instance_counts

    def create_distribution_analysis(self, instance_counts, bbox_data, all_bboxes):
        """ì¸ìŠ¤í„´ìŠ¤ ë¶„í¬ ë¶„ì„ ì‹œê°í™” ìƒì„±"""
        print("\nğŸ“Š ë¶„í¬ ë¶„ì„ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        # 4ê°œ ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('YOLO Dataset Instance Distribution Analysis', fontsize=16, fontweight='bold')
        
        # 1. í´ë˜ìŠ¤ë³„ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ (ë§‰ëŒ€ ê·¸ë˜í”„)
        class_ids = list(range(self.num_classes))
        counts = [instance_counts.get(i, 0) for i in class_ids]
        
        # ìƒ‰ìƒ ì„¤ì • (ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ì— ë”°ë¼)
        colors = []
        for count in counts:
            if count >= self.target_instances:
                colors.append('#2E8B57')  # ì´ˆë¡ (ë‹¬ì„±)
            elif count >= self.target_instances * 0.8:
                colors.append('#FFD700')  # ê¸ˆìƒ‰ (ê·¼ì ‘)
            elif count >= self.target_instances * 0.5:
                colors.append('#FF8C00')  # ì˜¤ë Œì§€ (ë¶€ì¡±)
            else:
                colors.append('#DC143C')  # ë¹¨ê°• (ë§¤ìš° ë¶€ì¡±)
        
        bars = ax1.bar(class_ids, counts, color=colors, alpha=0.7)
        ax1.axhline(y=self.target_instances, color='red', linestyle='--', linewidth=2, label=f'Target ({self.target_instances})')
        ax1.set_xlabel('Class ID')
        ax1.set_ylabel('Number of Instances')
        ax1.set_title('Instances per Class')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for bar, count in zip(bars, counts):
            if count > 0:
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,
                        str(count), ha='center', va='bottom', fontsize=8)
        
        # 2. í´ë˜ìŠ¤ë³„ ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸° ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯)
        if bbox_data:
            # ê° í´ë˜ìŠ¤ë³„ ë©´ì  ë°ì´í„° ìˆ˜ì§‘
            class_areas = []
            class_labels = []
            
            for class_id in sorted(bbox_data.keys()):
                if bbox_data[class_id]:  # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                    areas = [bbox['area'] for bbox in bbox_data[class_id]]
                    class_areas.append(areas)
                    class_labels.append(f'{class_id}')
            
            if class_areas:
                box_plot = ax2.boxplot(class_areas, labels=class_labels, patch_artist=True)
                
                # ë°•ìŠ¤ ìƒ‰ìƒ ì„¤ì •
                for i, (patch, class_id) in enumerate(zip(box_plot['boxes'], sorted(bbox_data.keys()))):
                    count = instance_counts.get(class_id, 0)
                    if count >= self.target_instances:
                        patch.set_facecolor('#2E8B57')
                    elif count >= self.target_instances * 0.8:
                        patch.set_facecolor('#FFD700')
                    elif count >= self.target_instances * 0.5:
                        patch.set_facecolor('#FF8C00')
                    else:
                        patch.set_facecolor('#DC143C')
                    patch.set_alpha(0.7)
                
                ax2.set_xlabel('Class ID')
                ax2.set_ylabel('Bounding Box Area')
                ax2.set_title('Bounding Box Size Distribution by Class')
                ax2.grid(True, alpha=0.3)
        
        # 3. ë°”ìš´ë”©ë°•ìŠ¤ ì¤‘ì‹¬ì  ë¶„í¬ (ì‚°ì ë„)
        if all_bboxes:
            x_centers = [bbox['x_center'] for bbox in all_bboxes]
            y_centers = [bbox['y_center'] for bbox in all_bboxes]
            
            # ë°€ë„ ê¸°ë°˜ ìƒ‰ìƒ ë§¤í•‘ì„ ìœ„í•œ íˆíŠ¸ë§µ
            hist, xedges, yedges = np.histogram2d(x_centers, y_centers, bins=50, range=[[0,1], [0,1]])
            extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]
            
            im3 = ax3.imshow(hist.T, extent=extent, origin='lower', cmap='Blues', alpha=0.7)
            ax3.scatter(x_centers, y_centers, c='darkblue', alpha=0.3, s=1)
            ax3.set_xlabel('X Center (normalized)')
            ax3.set_ylabel('Y Center (normalized)')
            ax3.set_title('Bounding Box Center Distribution')
            ax3.set_xlim(0, 1)
            ax3.set_ylim(0, 1)
            plt.colorbar(im3, ax=ax3, label='Density')
        
        # 4. ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸° ë¶„í¬ (width vs height)
        if all_bboxes:
            widths = [bbox['width'] for bbox in all_bboxes]
            heights = [bbox['height'] for bbox in all_bboxes]
            
            # ë°€ë„ ê¸°ë°˜ ìƒ‰ìƒ ë§¤í•‘
            hist, xedges, yedges = np.histogram2d(widths, heights, bins=50, range=[[0,1], [0,1]])
            extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]
            
            im4 = ax4.imshow(hist.T, extent=extent, origin='lower', cmap='Blues', alpha=0.7)
            ax4.scatter(widths, heights, c='darkblue', alpha=0.3, s=1)
            ax4.set_xlabel('Width (normalized)')
            ax4.set_ylabel('Height (normalized)')
            ax4.set_title('Bounding Box Size Distribution')
            ax4.set_xlim(0, 1)
            ax4.set_ylim(0, 1)
            plt.colorbar(im4, ax=ax4, label='Density')
        
        plt.tight_layout()
        
        # ì €ì¥
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        save_path = self.dataset_path / f"distribution_analysis_{timestamp}.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š ë¶„í¬ ë¶„ì„ ì €ì¥: {save_path}")
        
        # í†µê³„ ìš”ì•½ ì¶œë ¥
        if all_bboxes:
            areas = [bbox['area'] for bbox in all_bboxes]
            widths = [bbox['width'] for bbox in all_bboxes]
            heights = [bbox['height'] for bbox in all_bboxes]
            
            print(f"\nğŸ“ˆ ë°”ìš´ë”©ë°•ìŠ¤ í†µê³„:")
            print(f"   í‰ê·  ë©´ì : {np.mean(areas):.4f}")
            print(f"   í‰ê·  ë„ˆë¹„: {np.mean(widths):.4f}")
            print(f"   í‰ê·  ë†’ì´: {np.mean(heights):.4f}")
            print(f"   ì‘ì€ ê°ì²´ (ë©´ì  < 0.01): {sum(1 for a in areas if a < 0.01)}ê°œ ({sum(1 for a in areas if a < 0.01)/len(areas)*100:.1f}%)")
            print(f"   í° ê°ì²´ (ë©´ì  > 0.1): {sum(1 for a in areas if a > 0.1)}ê°œ ({sum(1 for a in areas if a > 0.1)/len(areas)*100:.1f}%)")
        
        plt.show()
        
        return save_path

    def create_augmentation_transform(self, strategy):
        """ì¦ê°• ì „ëµë³„ ë³€í™˜ ìƒì„± (ë¼ë²¨ í˜¸í™˜ ë³€í™˜ë§Œ)"""
        
        if strategy == 'extreme':
            return A.Compose([
                # ìƒ‰ìƒ ë³€í™” (ë¸Œëœë“œ ìƒ‰ìƒ ë³´ì¡´ ê³ ë ¤)
                A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.08, hue=0.02, p=0.7),
                A.RandomBrightnessContrast(brightness_limit=0.08, contrast_limit=0.08, p=0.6),
                
                # ê¸°í•˜í•™ì  ë³€í™˜ (ë¼ë²¨ê³¼ ë™ê¸°í™” ê°€ëŠ¥í•œ ê²ƒë§Œ)
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.1),
                A.Rotate(limit=10, border_mode=cv2.BORDER_CONSTANT, p=0.4),
                A.ShiftScaleRotate(
                    shift_limit=0.05, scale_limit=0.1, rotate_limit=8,
                    border_mode=cv2.BORDER_CONSTANT, p=0.4
                ),
                
                # í’ˆì§ˆ ë³€í™”
                A.OneOf([
                    A.GaussNoise(var_limit=(5.0, 20.0)),
                    A.ISONoise(color_shift=(0.01, 0.03), intensity=(0.1, 0.3)),
                ], p=0.3),
                
                A.OneOf([
                    A.GaussianBlur(blur_limit=3),
                    A.MotionBlur(blur_limit=3),
                    A.Sharpen(alpha=(0.1, 0.3)),
                ], p=0.3),
                
            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
            
        elif strategy == 'aggressive':
            return A.Compose([
                A.ColorJitter(brightness=0.08, contrast=0.08, saturation=0.06, hue=0.015, p=0.6),
                A.RandomBrightnessContrast(brightness_limit=0.06, contrast_limit=0.06, p=0.5),
                
                A.HorizontalFlip(p=0.5),
                A.Rotate(limit=6, border_mode=cv2.BORDER_CONSTANT, p=0.3),
                A.ShiftScaleRotate(
                    shift_limit=0.03, scale_limit=0.08, rotate_limit=5,
                    border_mode=cv2.BORDER_CONSTANT, p=0.3
                ),
                
                A.GaussNoise(var_limit=(3.0, 15.0), p=0.25),
                A.OneOf([
                    A.GaussianBlur(blur_limit=3),
                    A.Sharpen(alpha=(0.1, 0.2)),
                ], p=0.25),
                
            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
            
        elif strategy == 'moderate':
            return A.Compose([
                A.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.04, hue=0.01, p=0.5),
                A.RandomBrightnessContrast(brightness_limit=0.04, contrast_limit=0.04, p=0.4),
                
                A.HorizontalFlip(p=0.5),
                A.Rotate(limit=3, border_mode=cv2.BORDER_CONSTANT, p=0.2),
                
                A.GaussNoise(var_limit=(2.0, 10.0), p=0.2),
                A.GaussianBlur(blur_limit=3, p=0.2),
                
            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
            
        else:  # light
            return A.Compose([
                A.ColorJitter(brightness=0.03, contrast=0.03, saturation=0.02, hue=0.005, p=0.4),
                A.RandomBrightnessContrast(brightness_limit=0.03, contrast_limit=0.03, p=0.3),
                
                A.HorizontalFlip(p=0.5),
                A.GaussNoise(var_limit=(1.0, 5.0), p=0.15),
                
            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))

    def normalize_label_precision(self, labels):
        """ë¼ë²¨ ì¢Œí‘œë¥¼ 6ìë¦¬ ì •ë°€ë„ë¡œ í†µì¼"""
        normalized_labels = []
        for label in labels:
            line = label.strip()
            if not line:
                continue
                
            parts = line.split()
            if len(parts) >= 5:
                try:
                    class_id = int(parts[0])
                    x, y, w, h = map(float, parts[1:5])
                    
                    # 6ìë¦¬ ì •ë°€ë„ë¡œ í†µì¼
                    normalized_line = f"{class_id} {x:.6f} {y:.6f} {w:.6f} {h:.6f}"
                    normalized_labels.append(normalized_line)
                    
                except (ValueError, IndexError):
                    continue
        
        return normalized_labels

    def perform_data_augmentation(self, augmentation_plans):
        """ë‹¨ìˆœ ì¦í­ ë°ì´í„° ì¦ê°• ìˆ˜í–‰"""
        if not augmentation_plans:
            print("âœ… ëª¨ë“  í´ë˜ìŠ¤ê°€ ëª©í‘œ ë‹¬ì„±!")
            return True
        
        print(f"\nğŸ¨ ë‹¨ìˆœ ì¦í­ ë°ì´í„° ì¦ê°• ì‹œì‘...")
        print(f"ğŸ“‹ ì¦ê°• ëŒ€ìƒ: {len(augmentation_plans)}ê°œ í´ë˜ìŠ¤")
        print(f"ğŸ”§ ë°©ì‹: ì „ì²´ ì´ë¯¸ì§€ ì¦ê°• (ë¼ë²¨ ì •í™•ì„± ë³´ì¥)")
        
        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        backup_dir = self.dataset_path / "backup_before_augmentation"
        if not backup_dir.exists():
            backup_dir.mkdir()
            train_backup = backup_dir / "train"
            train_backup.mkdir()
            shutil.copytree(self.dataset_path / "train" / "images", train_backup / "images")
            shutil.copytree(self.dataset_path / "train" / "labels", train_backup / "labels")
            print(f"ğŸ“¦ ë°±ì—… ìƒì„±: {backup_dir}")
        
        total_created = 0
        
        for class_id, plan in augmentation_plans.items():
            class_name = plan['name']
            needed = plan['needed']
            sources = plan['sources']
            strategy = plan['strategy']
            
            print(f"\nğŸ¯ {class_name} (ID: {class_id})")
            print(f"   í˜„ì¬: {plan['current']}ê°œ, í•„ìš”: {needed}ê°œ")
            print(f"   ì†ŒìŠ¤ ì´ë¯¸ì§€: {len(sources)}ê°œ")
            print(f"   ì „ëµ: {strategy}")
            
            if not sources:
                print(f"   âŒ ì†ŒìŠ¤ ì´ë¯¸ì§€ ì—†ìŒ")
                continue
            
            # ë³€í™˜ ìƒì„±
            transform = self.create_augmentation_transform(strategy)
            
            created = 0
            
            # í•„ìš”í•œ ë§Œí¼ ì¦ê°• ì´ë¯¸ì§€ ìƒì„±
            while created < needed:
                try:
                    # ëœë¤ ì†ŒìŠ¤ ì´ë¯¸ì§€ ì„ íƒ
                    source_image = random.choice(sources)
                    
                    # ì´ë¯¸ì§€ ë¡œë“œ
                    image = cv2.imread(source_image['image_path'])
                    if image is None:
                        continue
                    
                    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    h, w = image_rgb.shape[:2]
                    
                    # ë¼ë²¨ ë¡œë“œ ë° ì •ê·œí™”
                    normalized_labels = self.normalize_label_precision(source_image['labels'])
                    
                    if not normalized_labels:
                        continue
                    
                    # YOLO í˜•ì‹ ë°”ìš´ë”©ë°•ìŠ¤ ì¤€ë¹„
                    bboxes = []
                    class_labels = []
                    
                    for label_line in normalized_labels:
                        parts = label_line.split()
                        if len(parts) >= 5:
                            try:
                                label_class_id = int(parts[0])
                                x, y, bbox_w, bbox_h = map(float, parts[1:5])
                                
                                # ë°”ìš´ë”©ë°•ìŠ¤ ë²”ìœ„ ì²´í¬
                                if (0 <= x <= 1 and 0 <= y <= 1 and 
                                    0 < bbox_w <= 1 and 0 < bbox_h <= 1):
                                    bboxes.append([x, y, bbox_w, bbox_h])
                                    class_labels.append(label_class_id)
                                    
                            except (ValueError, IndexError):
                                continue
                    
                    if not bboxes:
                        continue
                    
                    # ì¦ê°• ì ìš© (ë¼ë²¨ê³¼ ë™ê¸°í™”)
                    augmented = transform(image=image_rgb, bboxes=bboxes, class_labels=class_labels)
                    aug_image = augmented['image']
                    aug_bboxes = augmented['bboxes']
                    aug_class_labels = augmented['class_labels']
                    
                    # ì¦ê°• í›„ì—ë„ ë°”ìš´ë”©ë°•ìŠ¤ê°€ ìœ íš¨í•œì§€ í™•ì¸
                    if not aug_bboxes or len(aug_bboxes) != len(aug_class_labels):
                        continue
                    
                    # íŒŒì¼ëª… ìƒì„±
                    base_name = Path(source_image['image_path']).stem
                    aug_name = f"{base_name}_aug_{class_name}_{created:04d}"
                    
                    # ì´ë¯¸ì§€ ì €ì¥
                    aug_img_path = self.dataset_path / "train" / "images" / f"{aug_name}.jpg"
                    aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)
                    cv2.imwrite(str(aug_img_path), aug_image_bgr, [cv2.IMWRITE_JPEG_QUALITY, 95])
                    
                    # ë¼ë²¨ ì €ì¥ (6ìë¦¬ ì •ë°€ë„)
                    aug_label_path = self.dataset_path / "train" / "labels" / f"{aug_name}.txt"
                    
                    with open(aug_label_path, 'w') as f:
                        for bbox, label_id in zip(aug_bboxes, aug_class_labels):
                            x, y, bbox_w, bbox_h = bbox
                            # ë²”ìœ„ ì¬í™•ì¸ í›„ ì €ì¥
                            x = max(0.0, min(1.0, x))
                            y = max(0.0, min(1.0, y))
                            bbox_w = max(0.001, min(1.0, bbox_w))
                            bbox_h = max(0.001, min(1.0, bbox_h))
                            
                            f.write(f"{int(label_id)} {x:.6f} {y:.6f} {bbox_w:.6f} {bbox_h:.6f}\n")
                    
                    created += 1
                    
                    if created % 50 == 0:
                        print(f"   ğŸ“ˆ ì§„í–‰: {created}/{needed}")
                
                except Exception as e:
                    # ì‹¤íŒ¨í•œ ê²½ìš° ë‹¤ë¥¸ ì†ŒìŠ¤ë¡œ ë‹¤ì‹œ ì‹œë„
                    continue
            
            print(f"   âœ… {class_name} ì™„ë£Œ: {created}ê°œ ì´ë¯¸ì§€ ìƒì„±")
            total_created += created
        
        print(f"\nğŸ‰ ë‹¨ìˆœ ì¦í­ ë°ì´í„° ì¦ê°• ì™„ë£Œ! ì´ ìƒì„±: {total_created}ê°œ")
        print(f"ğŸ’¡ ë¼ë²¨ ì •í™•ì„±: 100% ë³´ì¥ (ì „ì²´ ì´ë¯¸ì§€ ì¦ê°•)")
        print(f"ğŸ¯ Copy-Paste/Mosaic: í›ˆë ¨ ë‹¨ê³„ì—ì„œ YOLO ë‚´ì¥ ê¸°ëŠ¥ í™œìš© ì˜ˆì •")
        return True

    def update_yaml_file(self):
        """data.yaml íŒŒì¼ ì—…ë°ì´íŠ¸ (ê²½ë¡œ ì •ë³´ ë“±)"""
        yaml_path = self.dataset_path / "data.yaml"
        
        # ë°±ì—…
        backup_path = yaml_path.with_suffix('.yaml.backup')
        if not backup_path.exists():
            shutil.copy2(yaml_path, backup_path)
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
        dataset_abs_path = self.dataset_path.resolve()
        
        updated_config = {
            'path': str(dataset_abs_path),
            'train': 'train/images',
            'val': 'val/images', 
            'test': 'test/images',
            'nc': self.num_classes,
            'names': self.class_names
        }
        
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(updated_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… data.yaml ì—…ë°ì´íŠ¸ ì™„ë£Œ")

    def validate_dataset(self):
        """ë°ì´í„°ì…‹ ìœ íš¨ì„± ê²€ì‚¬"""
        print("\nğŸ” ë°ì´í„°ì…‹ ìœ íš¨ì„± ê²€ì‚¬...")
        
        issues = []
        total_images = 0
        total_labels = 0
        
        for split in ['train', 'val', 'test']:
            images_dir = self.dataset_path / split / "images"
            labels_dir = self.dataset_path / split / "labels"
            
            if not images_dir.exists():
                issues.append(f"âŒ {split}/images í´ë” ì—†ìŒ")
                continue
            
            if not labels_dir.exists():
                issues.append(f"âŒ {split}/labels í´ë” ì—†ìŒ")
                continue
            
            images = list(images_dir.glob("*"))
            labels = list(labels_dir.glob("*.txt"))
            
            total_images += len(images)
            total_labels += len(labels)
            
            print(f"ğŸ“ {split}: ì´ë¯¸ì§€ {len(images)}ê°œ, ë¼ë²¨ {len(labels)}ê°œ")
            
            # ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ í™•ì¸
            unmatched = 0
            for img_file in images:
                if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                    label_file = labels_dir / (img_file.stem + '.txt')
                    if not label_file.exists():
                        unmatched += 1
            
            if unmatched > 0:
                issues.append(f"âš ï¸ {split}: {unmatched}ê°œ ì´ë¯¸ì§€ì— ë¼ë²¨ ì—†ìŒ")
        
        print(f"\nğŸ“Š ì „ì²´: ì´ë¯¸ì§€ {total_images}ê°œ, ë¼ë²¨ {total_labels}ê°œ")
        
        if issues:
            print("\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in issues:
                print(f"   {issue}")
        else:
            print("âœ… ë°ì´í„°ì…‹ ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼!")
        
        return len(issues) == 0

    def run_balance_pipeline(self):
        """ê· í˜• ì¡°ì ˆ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸ¯ YOLO ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ê· í˜• ì¡°ì ˆ íŒŒì´í”„ë¼ì¸ (ë‹¨ìˆœ ì¦í­)")
        print("=" * 60)
        
        try:
            # 1. ë°ì´í„°ì…‹ ìœ íš¨ì„± ê²€ì‚¬
            print("1ï¸âƒ£ ë°ì´í„°ì…‹ ìœ íš¨ì„± ê²€ì‚¬")
            if not self.validate_dataset():
                print("âŒ ë°ì´í„°ì…‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì • í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                return False
            
            # 2. ì¸ìŠ¤í„´ìŠ¤ ë¶„í¬ ë¶„ì„
            print("\n2ï¸âƒ£ í´ë˜ìŠ¤ë³„ ì¸ìŠ¤í„´ìŠ¤ ë¶„í¬ ë¶„ì„")
            augmentation_plans, current_counts = self.analyze_instance_distribution()
            
            # 3. ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±
            print("\nğŸ“· ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±")
            self.save_sample_images(current_counts, augmentation_plans)
            
            # 4. ì¦ê°• í•„ìš”ì„± í™•ì¸
            if not augmentation_plans:
                print("\nâœ… ëª¨ë“  í´ë˜ìŠ¤ê°€ ì´ë¯¸ ëª©í‘œë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
                return True
            
            print(f"\nğŸ“‹ ì¦ê°• ê³„íš:")
            total_needed = sum(plan['needed'] for plan in augmentation_plans.values())
            print(f"   ëŒ€ìƒ í´ë˜ìŠ¤: {len(augmentation_plans)}ê°œ")
            print(f"   ìƒì„±í•  ì´ë¯¸ì§€: {total_needed}ê°œ")
            print(f"   ë°©ì‹: ì „ì²´ ì´ë¯¸ì§€ ì¦ê°• (ë¼ë²¨ ì •í™•ì„± ë³´ì¥)")
            
            # 5. ì‚¬ìš©ì í™•ì¸
            proceed = input("\në‹¨ìˆœ ì¦í­ ë°ì´í„° ì¦ê°•ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
            if proceed not in ['y', 'yes']:
                print("âŒ ì¦ê°• ì·¨ì†Œë¨")
                return False
            
            # 6. ë°ì´í„° ì¦ê°• ì‹¤í–‰
            print("\n3ï¸âƒ£ ë‹¨ìˆœ ì¦í­ ë°ì´í„° ì¦ê°• ì‹¤í–‰")
            if not self.perform_data_augmentation(augmentation_plans):
                print("âŒ ë°ì´í„° ì¦ê°• ì‹¤íŒ¨")
                return False
            
            # 7. ê²°ê³¼ ë¶„ì„
            print("\n4ï¸âƒ£ ì¦ê°• í›„ ë¶„í¬ ì¬ë¶„ì„")
            final_plans, final_counts = self.analyze_instance_distribution()
            
            # 8. ìµœì¢… ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±
            print("\nğŸ“· ìµœì¢… ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±")
            self.save_sample_images(final_counts, final_plans)
            
            # 9. YAML ì—…ë°ì´íŠ¸
            print("\n5ï¸âƒ£ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸")
            self.update_yaml_file()
            
            # 10. ìµœì¢… ê²€ì‚¬
            print("\n6ï¸âƒ£ ìµœì¢… ìœ íš¨ì„± ê²€ì‚¬")
            self.validate_dataset()
            
            print(f"\nğŸ‰ í´ë˜ìŠ¤ ê· í˜• ì¡°ì ˆ ì™„ë£Œ!")
            print(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
            
            improved_classes = 0
            for class_id in range(self.num_classes):
                before = current_counts.get(class_id, 0)
                after = final_counts.get(class_id, 0)
                if after > before:
                    improved_classes += 1
                    print(f"   {self.class_names[class_id]}: {before} â†’ {after} (+{after-before})")
            
            print(f"âœ… {improved_classes}ê°œ í´ë˜ìŠ¤ ê°œì„ ë¨")
            print(f"\nğŸ“· ìƒì„±ëœ íŒŒì¼:")
            print(f"   ğŸ“ ìƒ˜í”Œ ì´ë¯¸ì§€: {self.dataset_path}/sample_images/")
            print(f"   ğŸ’¡ ê° í´ë˜ìŠ¤ë³„ í´ë”ì—ì„œ ë°”ìš´ë”©ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ìƒ˜í”Œ í™•ì¸ ê°€ëŠ¥")
            
            print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
            print(f"   ğŸ”„ train_model.pyì—ì„œ copy_paste, mosaic í™œì„±í™” ê¶Œì¥")
            print(f"   ğŸ“ˆ YOLO ë‚´ì¥ ê¸°ëŠ¥ìœ¼ë¡œ ë” ì •êµí•œ í•©ì„± ìˆ˜í–‰")
            
            return True
            
        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return False

    def restore_backup(self):
        """ë°±ì—…ì—ì„œ ë³µì›"""
        backup_dir = self.dataset_path / "backup_before_augmentation"
        if not backup_dir.exists():
            print("âŒ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        print("ğŸ”„ ë°±ì—…ì—ì„œ ë³µì› ì¤‘...")
        
        # í˜„ì¬ train í´ë” ì œê±°
        train_dir = self.dataset_path / "train"
        if train_dir.exists():
            shutil.rmtree(train_dir)
        
        # ë°±ì—…ì—ì„œ ë³µì›
        shutil.copytree(backup_dir / "train", train_dir)
        
        print("âœ… ë°±ì—…ì—ì„œ ë³µì› ì™„ë£Œ")
        return True

    def save_sample_images(self, current_counts, augmentation_plans=None, samples_per_class=3):
        """í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ (ë°”ìš´ë”©ë°•ìŠ¤ í¬í•¨)"""
        print(f"\nğŸ“· í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ì¤‘... (í´ë˜ìŠ¤ë‹¹ {samples_per_class}ê°œ)")
        
        # ìƒ˜í”Œ ì €ì¥ í´ë” ìƒì„±
        samples_dir = self.dataset_path / "sample_images"
        if samples_dir.exists():
            shutil.rmtree(samples_dir)
        samples_dir.mkdir()
        
        labels_dir = self.dataset_path / "train" / "labels"
        images_dir = self.dataset_path / "train" / "images"
        
        # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ì§‘
        class_samples = defaultdict(list)
        
        for label_file in labels_dir.glob("*.txt"):
            # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            image_file = None
            for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:
                potential_image = images_dir / (label_file.stem + ext)
                if potential_image.exists():
                    image_file = potential_image
                    break
            
            if not image_file:
                continue
            
            try:
                with open(label_file, 'r') as f:
                    lines = f.readlines()
                
                # ì´ ì´ë¯¸ì§€ì— ìˆëŠ” í´ë˜ìŠ¤ë“¤ í™•ì¸
                classes_in_image = set()
                for line in lines:
                    line = line.strip()
                    if line:
                        parts = line.split()
                        if len(parts) >= 5:
                            try:
                                class_id = int(parts[0])
                                if 0 <= class_id < self.num_classes:
                                    classes_in_image.add(class_id)
                            except:
                                continue
                
                # ê° í´ë˜ìŠ¤ë³„ë¡œ ìƒ˜í”Œ ì¶”ê°€
                for class_id in classes_in_image:
                    if len(class_samples[class_id]) < samples_per_class:
                        class_samples[class_id].append({
                            'image_path': str(image_file),
                            'label_path': str(label_file),
                            'labels': lines
                        })
                        
            except Exception as e:
                continue
        
        # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±
        for class_id in range(self.num_classes):
            class_name = self.class_names[class_id]
            current_count = current_counts.get(class_id, 0)
            
            if class_id not in class_samples:
                print(f"   âš ï¸ {class_name}: ìƒ˜í”Œ ì—†ìŒ")
                continue
            
            # í´ë˜ìŠ¤ í´ë” ìƒì„±
            class_dir = samples_dir / f"class_{class_id:02d}_{class_name}"
            class_dir.mkdir()
            
            # ìƒíƒœ ì •ë³´ íŒŒì¼ ìƒì„±
            status_info = {
                'class_id': class_id,
                'class_name': class_name,
                'current_instances': current_count,
                'target_instances': self.target_instances,
                'shortage': max(0, self.target_instances - current_count),
                'status': 'achieved' if current_count >= self.target_instances else 'needs_augmentation',
                'augmentation_method': 'simple_augmentation'
            }
            
            if augmentation_plans and class_id in augmentation_plans:
                plan = augmentation_plans[class_id]
                status_info.update({
                    'augmentation_strategy': plan['strategy'],
                    'planned_creation': plan['needed']
                })
            
            with open(class_dir / "status.json", 'w', encoding='utf-8') as f:
                json.dump(status_info, f, indent=2, ensure_ascii=False)
            
            # ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì— ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê³  ì €ì¥
            for i, sample in enumerate(class_samples[class_id]):
                try:
                    # ì´ë¯¸ì§€ ë¡œë“œ
                    image = cv2.imread(sample['image_path'])
                    if image is None:
                        continue
                    
                    h, w = image.shape[:2]
                    
                    # ë¼ë²¨ íŒŒì‹±í•˜ì—¬ ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    for line in sample['labels']:
                        line = line.strip()
                        if line:
                            parts = line.split()
                            if len(parts) >= 5:
                                try:
                                    label_class_id = int(parts[0])
                                    x_center, y_center, bbox_w, bbox_h = map(float, parts[1:5])
                                    
                                    # YOLO ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                                    x_center_px = int(x_center * w)
                                    y_center_px = int(y_center * h)
                                    bbox_w_px = int(bbox_w * w)
                                    bbox_h_px = int(bbox_h * h)
                                    
                                    x1 = int(x_center_px - bbox_w_px // 2)
                                    y1 = int(y_center_px - bbox_h_px // 2)
                                    x2 = int(x_center_px + bbox_w_px // 2)
                                    y2 = int(y_center_px + bbox_h_px // 2)
                                    
                                    # ë°”ìš´ë”©ë°•ìŠ¤ ìƒ‰ìƒ (íƒ€ê²Ÿ í´ë˜ìŠ¤ëŠ” ë¹¨ê°„ìƒ‰, ë‹¤ë¥¸ í´ë˜ìŠ¤ëŠ” íŒŒë€ìƒ‰)
                                    if label_class_id == class_id:
                                        color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                                        thickness = 3
                                    else:
                                        color = (255, 0, 0)  # íŒŒë€ìƒ‰ (BGR)
                                        thickness = 2
                                    
                                    # ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                                    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)
                                    
                                    # í´ë˜ìŠ¤ ë¼ë²¨ í‘œì‹œ
                                    if 0 <= label_class_id < len(self.class_names):
                                        label_text = f"{label_class_id}: {self.class_names[label_class_id]}"
                                        cv2.putText(image, label_text, (x1, y1-10), 
                                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness-1)
                                
                                except:
                                    continue
                    
                    # ì´ë¯¸ì§€ ì €ì¥
                    sample_filename = f"sample_{i+1:02d}.jpg"
                    sample_path = class_dir / sample_filename
                    cv2.imwrite(str(sample_path), image, [cv2.IMWRITE_JPEG_QUALITY, 90])
                    
                except Exception as e:
                    continue
            
            print(f"   ğŸ“ {class_name}: {len(class_samples[class_id])}ê°œ ìƒ˜í”Œ ì €ì¥")
        
        print(f"âœ… ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {samples_dir}")
        return samples_dir


# ì‹¤í–‰ë¶€
if __name__ == "__main__":
    print("ğŸ¯ YOLO ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ê· í˜• ì¡°ì ˆ ë„êµ¬ (ë‹¨ìˆœ ì¦í­)")
    print("=" * 50)
    
    # ì„¤ì •
    dataset_path = "/home/team06/workspace/jonghui/model/snack_data"
    target_instances = 600  # í´ë˜ìŠ¤ë‹¹ ëª©í‘œ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
    min_instances = 50     # ì¦ê°•ì„ ìœ„í•œ ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
    
    print(f"ğŸ“‚ ë°ì´í„°ì…‹: {dataset_path}")
    print(f"ğŸ¯ ëª©í‘œ: {target_instances}ê°œ/í´ë˜ìŠ¤")
    print(f"ğŸ“ ìµœì†Œ: {min_instances}ê°œ/í´ë˜ìŠ¤ (ì¦ê°• ì¡°ê±´)")
    print(f"ğŸ“· ìƒ˜í”Œ ì´ë¯¸ì§€: í´ë˜ìŠ¤ë³„ ë°”ìš´ë”©ë°•ìŠ¤ í¬í•¨ ìƒ˜í”Œ ìƒì„±")
    print(f"ğŸ”§ ë°©ì‹: ì „ì²´ ì´ë¯¸ì§€ ì¦ê°• (ë¼ë²¨ ì •í™•ì„± 100% ë³´ì¥)")
    
    # ë§¤ë‹ˆì € ìƒì„±
    try:
        manager = BalancedDatasetManager(
            dataset_path=dataset_path,
            target_instances=target_instances,
            min_instances=min_instances
        )
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        success = manager.run_balance_pipeline()
        
        if success:
            print(f"\nğŸŠ í´ë˜ìŠ¤ ê· í˜• ì¡°ì ˆ ì„±ê³µ!")
            print(f"ğŸ¯ ì´ì œ ëª¨ë“  í´ë˜ìŠ¤ê°€ ê· í˜•ì¡íŒ ìƒíƒœì…ë‹ˆë‹¤!")
            print(f"\nğŸ“· ìƒì„±ëœ íŒŒì¼ë“¤:")
            print(f"   ğŸ“ ìƒ˜í”Œ ì´ë¯¸ì§€: {dataset_path}/sample_images/")
            print(f"   ğŸ’¡ ê° í´ë˜ìŠ¤ë³„ í´ë”ì—ì„œ ë°”ìš´ë”©ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ìƒ˜í”Œ í™•ì¸")
            
            print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥:")
            print(f"   ğŸ”„ train_model.pyì—ì„œ copy_paste=0.3, mosaic=0.5 í™œì„±í™”")
            print(f"   ğŸ“ˆ YOLO ë‚´ì¥ ê¸°ëŠ¥ìœ¼ë¡œ ì •êµí•œ ê°ì²´ í•©ì„± ìˆ˜í–‰")
            print(f"   ğŸ’¯ ë¼ë²¨ ì •í™•ì„±ì€ ì´ë¯¸ 100% ë³´ì¥ë¨")
            
            # ë³µì› ì˜µì…˜
            restore = input("\në°±ì—…ì—ì„œ ë³µì›í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
            if restore in ['y', 'yes']:
                manager.restore_backup()
            else:
                print("ğŸ“Š ê· í˜•ì¡íŒ ë°ì´í„°ì…‹ ìœ ì§€")
        else:
            print(f"âŒ í´ë˜ìŠ¤ ê· í˜• ì¡°ì ˆ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()