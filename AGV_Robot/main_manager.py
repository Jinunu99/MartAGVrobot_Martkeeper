import threading
import time
import cv2
import numpy as np
from picamera2 import Picamera2

# ê¸°ì¡´ ëª¨ë“ˆë“¤
from utils.buffer import tx_queue, rx_queue
from communication import UARTHandler
from line_tracer import LineTracer
from qr import QRReader, SharedFrame, qr_thread_func
from communication.agv_to_server import AgvToServer

# ê´€ë¦¬ììš© ëª¨ë“ˆë“¤
from manager import ManagerPlanner, ManagerExecutor, DetectionController, ResourceManager

def start_uart():
    """UART ì†¡ìˆ˜ì‹  ìŠ¤ë ˆë“œ ì‹œì‘"""
    uart = UARTHandler(port='/dev/serial0', baudrate=19200)
    tx_t = threading.Thread(target=uart.uart_tx, daemon=True)
    rx_t = threading.Thread(target=uart.uart_rx, daemon=True)
    tx_t.start()
    rx_t.start()

def main_manager():
    """ê´€ë¦¬ì ë¡œë´‡ ë©”ì¸ í•¨ìˆ˜ (ìˆœí™˜ êµ¬ì¡° ì œê±°)"""
    print("ğŸ¤– ê´€ë¦¬ì ë¡œë´‡ ì‹œì‘!")
    print("ğŸ“‹ Detection í¬ì¸íŠ¸ ë„ë‹¬ ì‹œ Detection ì‹¤í–‰ ëª¨ë“œ")
    print("ğŸ¯ Detection ì¢Œí‘œ: [0,1], [0,3], [0,5], [4,5], [4,3], [4,1]")
    print("-" * 60)

    # 1) UART ì†¡ìˆ˜ì‹  ìŠ¤ë ˆë“œ ì‹œì‘
    start_uart()

    # 2) ì¹´ë©”ë¼ ì„¤ì •
    picam2 = Picamera2()
    picam2.configure(
        picam2.create_video_configuration(
            main={"format": "RGB888", "size": (640, 480)},
            controls={"FrameDurationLimits": (16666, 16666)}  # 60fps 16666, 16666
        )
    )



    
    picam2.start()

    # 3) ê¸°ë³¸ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”
    tracer = LineTracer()
    qr_reader = QRReader()
    agv_messenger = AgvToServer("managerAGV")
    agv_messenger.start()
    shared_frame = SharedFrame()

    # 4) QR ì¸ì‹ ìŠ¤ë ˆë“œ ì‹œì‘
    qr_thread = threading.Thread(
        target=qr_thread_func,
        args=(shared_frame, qr_reader, agv_messenger),
        daemon=True
    )
    qr_thread.start()

    # 5) ë§µ ì •ë³´
    grid = [[0, 0, 0, 0, 0, 0, 0],
            [0, 1, 0, 1, 0, 1, 0],
            [0, 0, 0, 0, 0, 0, 0],
            [0, 1, 0, 1, 0, 1, 0],
            [0, 0, 0, 0, 0, 0, 0],
            [0, 1, 1, 1, 1, 1, 0],
            [0, 0, 0, 0, 0, 0, 0]]

    # 6) ê´€ë¦¬ììš© ê°ì²´ë“¤ ì´ˆê¸°í™”
    planner = ManagerPlanner(grid)
    planner.set_now_position(6, 0)  # ì‹œì‘ ìœ„ì¹˜
    
    executor = ManagerExecutor(planner, tx_queue, tracer, start_dir='U')
    detection_controller = DetectionController()
    resource_manager = ResourceManager()

    # ìƒíƒœ ë³€ìˆ˜ë“¤
    last_detection_position = None  # ë§ˆì§€ë§‰ Detection ì‹¤í–‰ ìœ„ì¹˜
    detection_in_progress = False   # Detection ì§„í–‰ ì¤‘ í”Œë˜ê·¸

    print(f"[MAIN] ê´€ë¦¬ì ë¡œë´‡ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"[MAIN] Detection ê°€ëŠ¥ ì¢Œí‘œ: {planner.get_detection_coordinates()}")

    try:
        while True:
            frame = picam2.capture_array()
            shared_frame.set(frame)

            # QR IDë¡œ í˜„ì¬ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
            if agv_messenger.received_pos:
                print(f"[MAIN] ğŸ¯ ìœ„ì¹˜ ìˆ˜ì‹ ë¨! ({agv_messenger.position_x}, {agv_messenger.position_y})")
                x, y = agv_messenger.position_x, agv_messenger.position_y
                
                planner.set_now_position(x, y)
                current_position = [x, y]
                
                # Detection ìœ„ì¹˜ ë„ë‹¬ ì²´í¬ (ì´ì „ì— ì‹¤í–‰í•˜ì§€ ì•Šì€ ìœ„ì¹˜ì—ì„œë§Œ)
                if (planner.is_detection_point(x, y) and 
                    not detection_in_progress and
                    current_position != last_detection_position):
                    
                    print(f"[MAIN] ğŸ¯ ìƒˆë¡œìš´ Detection ìœ„ì¹˜ ë„ë‹¬: {current_position}")
                    
                    # Detection ì‹œì‘
                    detection_in_progress = True
                    last_detection_position = current_position.copy()
                    
                    # ìì› ì ˆì•½ì„ ìœ„í•œ ì¤€ë¹„
                    resource_manager.prepare_for_detection(picam2)
                    executor.stop_execution()  # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ëª…ë ¹ ì¤‘ì§€
                    
                    # Detection ì‹¤í–‰
                    print(f"[MAIN] ğŸ” Detection ì‹œì‘...")
                    detection_results = detection_controller.run_detection_cycle(max_wait_time=30)
                    
                    if detection_results:
                        print(f"[MAIN] âœ… Detection ì™„ë£Œ!")
                        print(f"[MAIN] ğŸ“Š ê²°ê³¼: {detection_results['count_summary']}")
                    else:
                        print(f"[MAIN] âŒ Detection ì‹¤íŒ¨ ë˜ëŠ” íƒ€ì„ì•„ì›ƒ")
                    
                    # ìì› ë³µì›
                    resource_manager.restore_after_detection(picam2)
                    
                    # ğŸ”¥ Detection ì™„ë£Œ í›„ ë¼ì¸ì„ ë”°ë¼ê°€ë©´ì„œ ì¡°ê¸ˆì”© ì´ë™
                    print(f"[MAIN] ğŸš— Detection ìœ„ì¹˜ì—ì„œ ë¼ì¸ì„ ë”°ë¼ ë²—ì–´ë‚˜ê¸°...")
                    move_count = 0
                    max_moves = 8  # ìµœëŒ€ 8ë²ˆ ì‹œë„
                    
                    while move_count < max_moves:
                        # í˜„ì¬ í”„ë ˆì„ìœ¼ë¡œ ë¼ì¸ ê°ì§€
                        current_frame = picam2.capture_array()
                        direction, offset, _, _, found = tracer.get_direction(current_frame)
                        
                        # ë¼ì¸ì„ ë”°ë¼ ì´ë™
                        if found and direction in ['F', 'L', 'R']:
                            tx_queue.put(direction + "\n")
                            time.sleep(0.3)  # ì§§ì€ ì´ë™
                            move_count += 1
                            print(f"[MAIN] ë¼ì¸ ì¶”ì¢… ì´ë™ {move_count}/{max_moves} - ë°©í–¥: {direction}")
                        else:
                            # ë¼ì¸ì´ ì—†ìœ¼ë©´ ì¡°ê¸ˆë§Œ ì „ì§„
                            tx_queue.put("F\n")
                            time.sleep(0.2)
                            move_count += 1
                            print(f"[MAIN] ì•ˆì „ ì „ì§„ {move_count}/{max_moves}")
                    
                    tx_queue.put("S\n")  # ì •ì§€
                    time.sleep(0.3)
                    
                    # ğŸ”¥ ì¶”ê°€: í”„ë ˆì„ ë²„í¼ í´ë¦¬ì–´ (ì¹´ë©”ë¼ ì•ˆì •í™”)
                    print(f"[MAIN] ğŸ“· í”„ë ˆì„ ë²„í¼ í´ë¦¬ì–´ ì¤‘...")
                    for _ in range(5):  # ì´ì „ í”„ë ˆì„ë“¤ ë²„ë¦¬ê¸°
                        frame = picam2.capture_array()
                        time.sleep(0.02)
                    print(f"[MAIN] âœ… í”„ë ˆì„ ë²„í¼ í´ë¦¬ì–´ ì™„ë£Œ")

                    # ì´ì œ ë¼ì¸íŠ¸ë ˆì´ì‹± ì¬ê°œ í—ˆìš©
                    detection_in_progress = False
                    print(f"[MAIN] ğŸ”„ ì¼ë°˜ ì£¼í–‰ ëª¨ë“œë¡œ ì „í™˜")
                
                agv_messenger.received_pos = False

            # ì£¼í–‰ ëª…ë ¹ ì‹¤í–‰ (Detection ì¤‘ì´ ì•„ë‹ ë•Œë§Œ)
            if resource_manager.is_line_tracer_active() and not detection_in_progress:
                # ë¼ì¸íŠ¸ë ˆì´ì„œ ë™ì‘
                direction, offset, annotated, binary, found = tracer.get_direction(frame)
                
                # ì‹¤í–‰ ì¤‘ì¸ ëª…ë ¹ì´ ìˆìœ¼ë©´ ì²˜ë¦¬
                if executor.is_executing():
                    # í•œ ì¹¸ ì „ì§„ ì™„ë£Œ ì²´í¬
                    if executor.command_queue and executor.command_queue[0] == 'F':
                        executor.command_queue.pop(0)

                    # íšŒì „ ëª…ë ¹ ì‹¤í–‰
                    if executor.command_queue and executor.command_queue[0] in ('R90', 'L90', 'B', 'B90'):
                        executor.execute_next_command(lambda: frame)

                # UART ì†¡ì‹  (ì¼ë°˜ ë¼ì¸ ì¶”ì¢…)
                tx_queue.put(direction + "\n")
                
                # ìƒíƒœ ì •ë³´ ì¶œë ¥
                status = planner.get_status()
                executor_status = executor.get_status()
                
                # print(f"[MAIN] Direction={direction}, Offset={offset}, Found={found}")
                # print(f"[MAIN] í˜„ì¬ìœ„ì¹˜: {status['current_position']}")
                # print(f"[MAIN] Detectioní¬ì¸íŠ¸: {status['is_at_detection_point']}")
                # print(f"[MAIN] ì‹¤í–‰ì¤‘: {executor_status['executing']}, ë‚¨ì€ëª…ë ¹: {executor_status['commands_remaining']}")
                
                # Detection ì¢Œí‘œ í‘œì‹œ
                # if status['is_at_detection_point']:
                #     print(f"[MAIN] ğŸ’¡ í˜„ì¬ Detection ê°€ëŠ¥ ìœ„ì¹˜ì— ìˆìŒ!")
            
            else:
                # Detection ì¤‘ì´ë¯€ë¡œ ì£¼í–‰ ì •ì§€
                tx_queue.put("S\n")

            # ë””ë²„ê¹… ì´ë¯¸ì§€ í‘œì‹œ (Detection ì¤‘ì´ ì•„ë‹ ë•Œë§Œ)
            if resource_manager.is_line_tracer_active() and not detection_in_progress:
                combined = tracer.draw_debug(annotated, binary)
                
                # Detection ì¢Œí‘œ í‘œì‹œ
                status = planner.get_status()
                if status['is_at_detection_point']:
                    cv2.putText(combined, "DETECTION POINT", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # cv2.imshow("Manager Robot - LineTracer", combined)

                # if cv2.waitKey(1) & 0xFF in (ord('q'), 27):
                #     break

            # time.sleep(0.015)

    except KeyboardInterrupt:
        print("\n[MAIN] ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­")
    except Exception as e:
        print(f"\n[MAIN] âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        print("[MAIN] ğŸ ê´€ë¦¬ì ë¡œë´‡ ì¢…ë£Œ ì¤‘...")
        tx_queue.put("S\n")
        detection_controller.stop_detection()
        picam2.stop()
        cv2.destroyAllWindows()
        print("[MAIN] âœ… ê´€ë¦¬ì ë¡œë´‡ ì¢…ë£Œ ì™„ë£Œ")

if __name__ == "__main__":
    main_manager()