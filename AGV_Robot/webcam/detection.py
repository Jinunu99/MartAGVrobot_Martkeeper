import cv2
import time
from ultralytics import YOLO
import numpy as np
from collections import deque

from webcam.tracker import ObjectTracker
from webcam.count_reports import print_count_report
from webcam.config import *

class SnackDetector:
    def __init__(self, model_path=MODEL_PATH):
        self.model_path = model_path
        self.model = None
        self.class_names = CLASS_NAMES
        
        # ì´ˆê¸°í™”
        self.cap = None
        self.tracker = None
        self.frame_count = 0
        self.conf_threshold = CONFIDENCE_THRESHOLD
        self.count_history = deque(maxlen=REPORT_CONFIG['max_count_history'])
        
    def initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = YOLO(self.model_path)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
    def initialize_camera(self):
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        print("ğŸ“¹ ì›¹ìº  ì´ˆê¸°í™” ì¤‘...")
        self.cap = cv2.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, CAMERA_CONFIG['buffer_size'])
        
        # USB 2.0ì— ìµœì í™”ëœ í•´ìƒë„
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_CONFIG['width'])
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_CONFIG['height'])
        
        # MJPEG ì½”ë±ìœ¼ë¡œ ì••ì¶• íš¨ìœ¨ í–¥ìƒ
        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
        self.cap.set(cv2.CAP_PROP_FOURCC, fourcc)
        self.cap.set(cv2.CAP_PROP_FPS, CAMERA_CONFIG['fps'])
        
        if not self.cap.isOpened():
            raise RuntimeError("âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        
        # ì‹¤ì œ í•´ìƒë„ í™•ì¸
        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"ğŸ“· ì‹¤ì œ í•´ìƒë„: {actual_width}x{actual_height}")
        
        # ì›Œë°ì—…
        print("ğŸ”¥ ì›¹ìº  ì›Œë°ì—…...")
        for i in range(CAMERA_CONFIG['warmup_frames']):
            ret, frame = self.cap.read()
            print(f"ì›Œë°ì—… {i+1}: {'OK' if ret else 'FAIL'}")
            time.sleep(0.2)
            
        return actual_width, actual_height
        
    def initialize_tracker(self):
        """ì¶”ì ê¸° ì´ˆê¸°í™”"""
        self.tracker = ObjectTracker(**TRACKER_CONFIG)
        
    def gui_test(self):
        """GUI ê¸°ë³¸ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª GUI ê¸°ë³¸ í…ŒìŠ¤íŠ¸...")
        test_img = np.zeros((200, 400, 3), dtype=np.uint8)
        test_img[50:150, 50:350] = [0, 255, 0]
        cv2.putText(test_img, "GUI Working!", (100, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        cv2.namedWindow('GUI Test', cv2.WINDOW_NORMAL)
        cv2.imshow('GUI Test', test_img)
        print("GUI í…ŒìŠ¤íŠ¸ ì°½ì´ ë³´ì´ë‚˜ìš”? 2ì´ˆ í›„ ìë™ìœ¼ë¡œ ë‹«í™ë‹ˆë‹¤.")
        cv2.waitKey(UI_CONFIG['gui_test_duration'])
        cv2.destroyAllWindows()
        
    def detect_objects(self, frame):
        """í”„ë ˆì„ì—ì„œ ê°ì²´ íƒì§€"""
        try:
            # í”„ë ˆì„ ì „ì²˜ë¦¬
            processed_frame = cv2.convertScaleAbs(frame, alpha=1.1, beta=5)
            
            start_time = time.time()
            
            # YOLO íƒì§€
            results = self.model(processed_frame, conf=self.conf_threshold, verbose=False)
            
            inference_time = time.time() - start_time
            print(f"â±ï¸ ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ")
            
            # í˜„ì¬ í”„ë ˆì„ íƒì§€ ê²°ê³¼
            current_detections = []
            
            if results and len(results) > 0:
                boxes = results[0].boxes
                
                if boxes is not None and len(boxes) > 0:
                    for box in boxes:
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])
                        
                        if class_id < len(self.class_names):
                            class_name = self.class_names[class_id]
                        else:
                            class_name = f"Unknown_{class_id}"
                        
                        current_detections.append({
                            'bbox': (x1, y1, x2, y2),
                            'name': class_name,
                            'confidence': confidence
                        })
                        
                        print(f"ğŸ¯ íƒì§€: {class_name} ({confidence:.2f})")
            
            return current_detections
            
        except Exception as e:
            print(f"âš ï¸ íƒì§€ ì˜¤ë¥˜: {e}")
            return []
            
    def draw_objects(self, frame, stable_objects, actual_width, actual_height, current_fps):
        """í”„ë ˆì„ì— íƒì§€ëœ ê°ì²´ë“¤ ê·¸ë¦¬ê¸°"""
        display_frame = frame.copy()
        
        # ì•ˆì •í™”ëœ ê°ì²´ë“¤ ê·¸ë¦¬ê¸°
        for obj in stable_objects:
            x1, y1, x2, y2 = obj['bbox']
            class_name = obj['name']
            confidence = obj['confidence']
            votes = obj['votes']
            stability = obj['stability']
            
            # ì•ˆì •ì„±ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€ê²½
            if stability > STABILITY_THRESHOLDS['very_stable']:
                color = COLORS['very_stable']    # ë§¤ìš° ì•ˆì •: ì´ˆë¡ìƒ‰
            elif stability > STABILITY_THRESHOLDS['stable']:
                color = COLORS['stable']         # ì•ˆì •: ë…¸ë€ìƒ‰
            elif stability > STABILITY_THRESHOLDS['moderate']:
                color = COLORS['moderate']       # ë³´í†µ: ì£¼í™©ìƒ‰
            else:
                color = COLORS['unstable']       # ë¶ˆì•ˆì •: ë³´ë¼ìƒ‰
            
            # ë°”ìš´ë”© ë°•ìŠ¤ (ë‘ê»˜ëŠ” ì•ˆì •ì„±ì— ë¹„ë¡€)
            thickness = max(1, int(stability * 4))
            cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, thickness)
            
            # ë¼ë²¨ (íˆ¬í‘œ ìˆ˜ì™€ ì•ˆì •ì„± í¬í•¨)
            label = f"{class_name}"
            confidence_label = f"Conf:{confidence:.2f}"
            stability_label = f"Votes:{votes}/Stab:{stability:.2f}"
            
            cv2.putText(display_frame, label, (x1, y1-30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            cv2.putText(display_frame, confidence_label, (x1, y1-15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            cv2.putText(display_frame, stability_label, (x1, y1-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # í˜„ì¬ ê°œìˆ˜ í†µê³„ í‘œì‹œ
        class_counts, total_count = self.tracker.get_count_summary()
        
        # ìƒíƒœ ì •ë³´ í‘œì‹œ (ì™¼ìª½)
        cv2.putText(display_frame, f"Frame: {self.frame_count}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, UI_CONFIG['font_scale'], COLORS['text'], UI_CONFIG['font_thickness'])
        cv2.putText(display_frame, f"FPS: {current_fps:.1f}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, UI_CONFIG['font_scale'], COLORS['text'], UI_CONFIG['font_thickness'])
        cv2.putText(display_frame, f"Total Objects: {total_count}", (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, UI_CONFIG['font_scale'], COLORS['count_text'], UI_CONFIG['font_thickness'])
        cv2.putText(display_frame, f"Conf Threshold: {self.conf_threshold:.2f}", (10, 120), 
                   cv2.FONT_HERSHEY_SIMPLEX, UI_CONFIG['font_scale'], COLORS['text'], UI_CONFIG['font_thickness'])
        
        # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ í‘œì‹œ (ì˜¤ë¥¸ìª½)
        y_offset = 30
        cv2.putText(display_frame, "Class Counts:", (actual_width-200, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLORS['class_text'], 2)
        
        for class_name, count in class_counts.items():
            if count > 0:
                y_offset += 25
                short_name = class_name.split('_')[0] if '_' in class_name else class_name[:10]
                cv2.putText(display_frame, f"{short_name}: {count}", 
                           (actual_width-200, y_offset), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS['text'], 1)
        
        return display_frame
        
    def handle_key_input(self, key, display_frame):
        """í‚¤ ì…ë ¥ ì²˜ë¦¬"""
        if key == KEY_MAPPINGS['quit']:
            return False
        elif key == KEY_MAPPINGS['screenshot']:
            filename = f"level2_detection_{self.frame_count}.jpg"
            cv2.imwrite(filename, display_frame)
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
        elif key == KEY_MAPPINGS['statistics']:
            class_counts, total_count = self.tracker.get_count_summary()
            print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ:")
            print(f"  í”„ë ˆì„: {self.frame_count}, ì´ ê°ì²´: {total_count}")
            print(f"  í´ë˜ìŠ¤ë³„: {dict(class_counts)}")
        elif key in KEY_MAPPINGS['increase_conf']:
            self.conf_threshold = min(CONFIDENCE_CONFIG['max_threshold'], 
                                    self.conf_threshold + CONFIDENCE_CONFIG['adjustment_step'])
            print(f"ğŸ“ˆ ì‹ ë¢°ë„ ì¦ê°€: {self.conf_threshold:.2f}")
        elif key == KEY_MAPPINGS['decrease_conf']:
            self.conf_threshold = max(CONFIDENCE_CONFIG['min_threshold'], 
                                    self.conf_threshold - CONFIDENCE_CONFIG['adjustment_step'])
            print(f"ğŸ“‰ ì‹ ë¢°ë„ ê°ì†Œ: {self.conf_threshold:.2f}")
        elif key == KEY_MAPPINGS['reset_tracker']:
            self.initialize_tracker()
            print("ğŸ”„ ì¶”ì ê¸° ë¦¬ì…‹ ì™„ë£Œ")
        elif key == KEY_MAPPINGS['count_report']:
            class_counts, total_count = self.tracker.get_count_summary()
            print_count_report(self.count_history, class_counts, total_count)
        
        return True
        
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        print("ğŸª Level 2 Multi-frame Voting ê°ì²´ ê°œìˆ˜ íŒŒì•… ì‹œìŠ¤í…œ")
        
        # ì´ˆê¸°í™”
        self.gui_test()
        self.initialize_model()
        actual_width, actual_height = self.initialize_camera()
        self.initialize_tracker()
        
        # OpenCV ì°½ ë¯¸ë¦¬ ìƒì„± ë° ì„¤ì •
        window_name = UI_CONFIG['window_name']
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, UI_CONFIG['window_width'], UI_CONFIG['window_height'])
        
        print("ğŸ¯ Level 2 ê°ì²´ ê°œìˆ˜ íŒŒì•… ì‹œì‘!")
        print("ì£¼ìš” ì¡°ì‘:")
        print("  'q': ì¢…ë£Œ")
        print("  'SPACE': ìŠ¤í¬ë¦°ìƒ·")
        print("  's': í†µê³„ ì¶œë ¥")
        print("  '+/-': ì‹ ë¢°ë„ ì¡°ì ˆ")
        print("  'r': ì¶”ì ê¸° ë¦¬ì…‹")
        print("  'c': ê°œìˆ˜ ì¹´ìš´íŒ… ë³´ê³ ì„œ")
        
        last_successful_frame = None
        
        # FPS ì¸¡ì •
        fps_start = time.time()
        fps_counter = 0
        current_fps = 0
        
        while True:
            ret, frame = self.cap.read()
            
            if not ret or frame is None:
                print(f"âŒ í”„ë ˆì„ {self.frame_count + 1} ì½ê¸° ì‹¤íŒ¨")
                
                if last_successful_frame is not None:
                    frame = last_successful_frame.copy()
                    cv2.putText(frame, "CAMERA ERROR - USING LAST FRAME", (10, actual_height-40), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                else:
                    frame = np.zeros((actual_height, actual_width, 3), dtype=np.uint8)
                    cv2.putText(frame, "CAMERA ERROR", (actual_width//2-100, actual_height//2), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
            else:
                last_successful_frame = frame.copy()
            
            self.frame_count += 1
            fps_counter += 1
             
            # FPS ê³„ì‚°
            if fps_counter >= FPS_CONFIG['measurement_interval']:
                current_time = time.time()
                current_fps = FPS_CONFIG['measurement_interval'] / (current_time - fps_start)
                fps_start = current_time
                fps_counter = 0
            
            # íƒì§€ëŠ” ì„¤ì •ëœ ê°„ê²©ë§ˆë‹¤
            if self.frame_count % CAMERA_CONFIG['detection_interval'] == 0 and ret:
                print(f"ğŸ” íƒì§€ ì‹¤í–‰... (í”„ë ˆì„ {self.frame_count})")
                current_detections = self.detect_objects(frame)
                
                # ì¶”ì ê¸° ì—…ë°ì´íŠ¸ (Level 2 Multi-frame Voting)
                stable_objects = self.tracker.update(current_detections)
                
                # ê°œìˆ˜ í†µê³„ ê¸°ë¡
                class_counts, total_count = self.tracker.get_count_summary()
                self.count_history.append({
                    'frame': self.frame_count,
                    'total': total_count,
                    'classes': dict(class_counts)
                })
            else:
                stable_objects = self.tracker.stable_objects
            
            # í™”ë©´ í‘œì‹œ
            display_frame = self.draw_objects(frame, stable_objects, actual_width, actual_height, current_fps)
            
            # ì¹´ë©”ë¼ ìƒíƒœ í‘œì‹œ
            status_color = (0, 255, 0) if ret else (0, 0, 255)
            status_text = "CAM OK" if ret else "CAM ERROR"
            cv2.putText(display_frame, status_text, (actual_width-150, actual_height-20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
            
            # í™”ë©´ ì—…ë°ì´íŠ¸
            try:
                cv2.imshow(window_name, display_frame)
            except Exception as e:
                print(f"âš ï¸ í™”ë©´ í‘œì‹œ ì˜¤ë¥˜: {e}")
            
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if not self.handle_key_input(key, display_frame):
                break
            
            # ì§„í–‰ìƒí™© ì£¼ê¸°ì  ì¶œë ¥
            if self.frame_count % REPORT_CONFIG['progress_report_interval'] == 0:
                class_counts, total_count = self.tracker.get_count_summary()
                print(f"ğŸ“Š ì§„í–‰: {self.frame_count} í”„ë ˆì„, FPS {current_fps:.1f}, ì´ ê°ì²´ {total_count}ê°œ")
        
        # ì •ë¦¬
        self.cap.release()
        cv2.destroyAllWindows()
        print("ğŸ”š Level 2 ê°ì²´ ê°œìˆ˜ íŒŒì•… ì‹œìŠ¤í…œ ì¢…ë£Œ")

# ê°„ë‹¨í•œ ì‹¤í–‰ í•¨ìˆ˜
def detect_start(model_path=MODEL_PATH):
    """ì›¹ìº  ê°ì²´ íƒì§€ ì‹œì‘ - ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œ í˜¸ì¶œìš©"""
    print("ğŸš€ ì›¹ìº  ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ ì‹œì‘...")
    detector = SnackDetector(model_path=model_path)
    detector.run()

def detect_stop():
    """ì›¹ìº  ê°ì²´ íƒì§€ ì¤‘ì§€ - í–¥í›„ í™•ì¥ìš©"""
    print("â¹ï¸ ì›¹ìº  ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ ì¤‘ì§€...")
    cv2.destroyAllWindows()