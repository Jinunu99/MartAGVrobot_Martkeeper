# detection/detector.py
"""ê°ì²´ ê²€ì¶œ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤ - íŒ€ í”„ë¡œì íŠ¸ í†µí•©ìš©"""

import cv2
import time
import numpy as np
import threading
from collections import deque

from .webcam.quant_webcam.config import *
from .coral_detector import CoralDetector
from .object_tracker import ObjectTracker

class ObjectDetectionSystem:
    """ê°ì²´ ê²€ì¶œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ - ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í˜¸ì¶œ ê°€ëŠ¥"""
    
    def __init__(self, model_path=None, labels_path=None, config_override=None):
        """
        ì´ˆê¸°í™”
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.py ì‚¬ìš©)
            labels_path: ë¼ë²¨ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.py ì‚¬ìš©)
            config_override: ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ dict
        """
        # ì„¤ì • ì ìš©
        if config_override:
            for key, value in config_override.items():
                if hasattr(globals(), key):
                    globals()[key] = value
        
        # ëª¨ë¸ ê²½ë¡œ
        self.model_path = model_path or MODEL_PATH
        self.labels_path = labels_path or LABELS_PATH
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.detector = None
        self.tracker = None
        self.cap = None
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_running = False
        self.is_initialized = False
        self.frame_count = 0
        self.current_fps = 0
        self.conf_threshold = CONF_THRESHOLD
        
        # ìµœì‹  ê²°ê³¼ ì €ì¥
        self.latest_frame = None
        self.latest_objects = []
        self.latest_counts = {}
        self.latest_total = 0
        
        # ìŠ¤ë ˆë“œ ê´€ë¦¬
        self.detection_thread = None
        self.lock = threading.Lock()
        
    def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            print("ğŸ¤– ê°ì²´ ê²€ì¶œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # ëª¨ë¸ ë¡œë“œ
            self.detector = CoralDetector(self.model_path, self.labels_path)
            
            # ì¶”ì ê¸° ì´ˆê¸°í™”
            self.tracker = ObjectTracker(
                max_history=MAX_HISTORY,
                min_votes=MIN_VOTES,
                iou_threshold=IOU_THRESHOLD,
                distance_threshold=DISTANCE_THRESHOLD
            )
            
            # ì›¹ìº  ì´ˆê¸°í™”
            self.cap = self._init_camera()
            if self.cap is None:
                raise Exception("ì›¹ìº  ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            self.is_initialized = True
            print("âœ… ê°ì²´ ê²€ì¶œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _init_camera(self):
        """ì›¹ìº  ì´ˆê¸°í™”"""
        print("ğŸ“¹ ì›¹ìº  ì´ˆê¸°í™” ì¤‘...")
        cap = cv2.VideoCapture(CAMERA_INDEX)
        
        # ì¤‘ìš”: ë²„í¼ ì‚¬ì´ì¦ˆ 1ë¡œ ì„¤ì •
        cap.set(cv2.CAP_PROP_BUFFERSIZE, BUFFER_SIZE)
        
        # í•´ìƒë„ ë° FPS ì„¤ì •
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)
        cap.set(cv2.CAP_PROP_FPS, FPS)
        
        # MJPEG ì½”ë±
        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
        cap.set(cv2.CAP_PROP_FOURCC, fourcc)
        
        if not cap.isOpened():
            return None
        
        # ì›Œë°ì—…
        for i in range(3):
            ret, frame = cap.read()
            if ret:
                print(f"ì›¹ìº  ì›Œë°ì—… {i+1}: OK")
        
        return cap
    
    def start_detection(self, show_window=True):
        """ê²€ì¶œ ì‹œì‘ (ìŠ¤ë ˆë“œ ê¸°ë°˜)"""
        if not self.is_initialized:
            if not self.initialize():
                return False
        
        if self.is_running:
            print("ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return True
        
        self.is_running = True
        self.detection_thread = threading.Thread(
            target=self._detection_loop, 
            args=(show_window,)
        )
        self.detection_thread.daemon = True
        self.detection_thread.start()
        
        print("ğŸ¯ ê°ì²´ ê²€ì¶œ ì‹œì‘!")
        return True
    
    def stop_detection(self):
        """ê²€ì¶œ ì¤‘ì§€"""
        self.is_running = False
        
        if self.detection_thread:
            self.detection_thread.join(timeout=2.0)
        
        if self.cap:
            self.cap.release()
        
        cv2.destroyAllWindows()
        print("ğŸ”š ê°ì²´ ê²€ì¶œ ì¤‘ì§€")
    
    def _detection_loop(self, show_window=True):
        """ê²€ì¶œ ë£¨í”„ (ë‚´ë¶€ í•¨ìˆ˜)"""
        fps_start = time.time()
        fps_counter = 0
        
        # ìœˆë„ìš° ìƒì„± (í•„ìš”ì‹œ)
        if show_window:
            window_name = 'Object Detection'
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        
        while self.is_running:
            ret, frame = self.cap.read()
            
            if not ret:
                print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                continue
            
            self.frame_count += 1
            fps_counter += 1
            
            # FPS ê³„ì‚°
            if fps_counter >= 30:
                current_time = time.time()
                self.current_fps = 30 / (current_time - fps_start)
                fps_start = current_time
                fps_counter = 0
            
            # ë§¤ 3í”„ë ˆì„ë§ˆë‹¤ ê²€ì¶œ
            if self.frame_count % 3 == 0:
                try:
                    # ê²€ì¶œ ìˆ˜í–‰
                    detections, inference_time = self.detector.detect(frame, self.conf_threshold)
                    
                    # ì¶”ì ê¸° ì—…ë°ì´íŠ¸
                    stable_objects = self.tracker.update(detections)
                    
                    # ê²°ê³¼ ì—…ë°ì´íŠ¸ (ìŠ¤ë ˆë“œ ì•ˆì „)
                    with self.lock:
                        self.latest_frame = frame.copy()
                        self.latest_objects = stable_objects.copy()
                        self.latest_counts, self.latest_total = self.tracker.get_count_summary()

                    # âœ… í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ì¶œë ¥
                    if self.latest_counts:
                        print("ğŸ“¦ í´ë˜ìŠ¤ë³„ ê²€ì¶œ ê²°ê³¼:")
                        for cls, count in self.latest_counts.items():
                            print(f"  - {cls}: {count}ê°œ")
                        print(f"ğŸ”¢ ì´ ê°ì²´ ìˆ˜: {self.latest_total}\n")
                    
                except Exception as e:
                    print(f"âš ï¸ ê²€ì¶œ ì˜¤ë¥˜: {e}")
            
            # í™”ë©´ í‘œì‹œ (í•„ìš”ì‹œ)
            if show_window:
                display_frame = self._draw_objects(frame.copy())
                cv2.imshow(window_name, display_frame)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    self.stop_detection()
                    break
    
    def _draw_objects(self, frame):
        """ê°ì²´ ê·¸ë¦¬ê¸°"""
        with self.lock:
            objects = self.latest_objects.copy()
            counts = self.latest_counts.copy()
            total = self.latest_total
        
        # ê°ì²´ ê·¸ë¦¬ê¸°
        for obj in objects:
            x1, y1, x2, y2 = obj['bbox']
            class_name = obj['name']
            confidence = obj['confidence']
            stability = obj['stability']
            
            # ìƒ‰ìƒ
            if stability > 0.8:
                color = (0, 255, 0)
            elif stability > 0.6:
                color = (0, 255, 255)
            else:
                color = (0, 165, 255)
            
            # ë°•ìŠ¤ì™€ ë¼ë²¨
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            short_name = class_name.split('_')[0] if '_' in class_name else class_name[:8]
            label = f"{short_name} {confidence:.2f}"
            cv2.putText(frame, label, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # ì •ë³´ í‘œì‹œ
        cv2.putText(frame, f"Frame: {self.frame_count}", (10, 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        cv2.putText(frame, f"FPS: {self.current_fps:.1f}", (10, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        cv2.putText(frame, f"Objects: {total}", (10, 75), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
        
        return frame
    
    def get_current_results(self):
        """í˜„ì¬ ê²€ì¶œ ê²°ê³¼ ë°˜í™˜ (ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í˜¸ì¶œ)"""
        with self.lock:
            return {
                'frame': self.latest_frame.copy() if self.latest_frame is not None else None,
                'objects': self.latest_objects.copy(),
                'class_counts': self.latest_counts.copy(),
                'total_count': self.latest_total,
                'fps': self.current_fps,
                'frame_number': self.frame_count
            }
    
    def get_object_counts(self):
        """ê°ì²´ ê°œìˆ˜ë§Œ ë°˜í™˜ (ê°„ë‹¨í•œ API)"""
        with self.lock:
            return self.latest_counts.copy(), self.latest_total
    
    def set_confidence_threshold(self, threshold):
        """ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •"""
        self.conf_threshold = max(0.1, min(0.9, threshold))
        print(f"ì‹ ë¢°ë„ ì„ê³„ê°’: {self.conf_threshold:.2f}")
    
    def reset_tracker(self):
        """ì¶”ì ê¸° ë¦¬ì…‹"""
        if self.tracker:
            self.tracker.reset()
            print("ğŸ”„ ì¶”ì ê¸° ë¦¬ì…‹")
    
    def is_detection_running(self):
        """ê²€ì¶œ ì‹¤í–‰ ìƒíƒœ í™•ì¸"""
        return self.is_running
    
    def get_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            'initialized': self.is_initialized,
            'running': self.is_running,
            'fps': self.current_fps,
            'frame_count': self.frame_count,
            'conf_threshold': self.conf_threshold
        }

def run_standalone():
    """ë…ë¦½ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸª Coral USB ê°ì²´ ê²€ì¶œ ì‹œìŠ¤í…œ (ë…ë¦½ ì‹¤í–‰)")
    
    # ì‹œìŠ¤í…œ ìƒì„±
    detection_system = ObjectDetectionSystem()
    
    # ì´ˆê¸°í™” ë° ì‹¤í–‰
    if detection_system.initialize():
        try:
            detection_system.start_detection(show_window=True)
            
            print("í‚¤ ì¡°ì‘:")
            print("  'q': ì¢…ë£Œ")
            print("  'SPACE': ê²°ê³¼ ì¶œë ¥")
            
            # ë©”ì¸ ë£¨í”„ (ê²°ê³¼ ëª¨ë‹ˆí„°ë§)
            while detection_system.is_detection_running():
                time.sleep(1)
                
                # ì£¼ê¸°ì  ìƒíƒœ ì¶œë ¥
                if detection_system.frame_count % 100 == 0:
                    results = detection_system.get_current_results()
                    print(f"ğŸ“Š ì§„í–‰: {results['frame_number']}í”„ë ˆì„, "
                          f"FPS {results['fps']:.1f}, "
                          f"ê°ì²´ {results['total_count']}ê°œ")
        
        except KeyboardInterrupt:
            print("\nì‚¬ìš©ì ì¤‘ë‹¨")
        
        finally:
            detection_system.stop_detection()
    
    else:
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")

if __name__ == "__main__":
    run_standalone()